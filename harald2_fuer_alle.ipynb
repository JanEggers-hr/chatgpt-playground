{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyEhMtiQEHEiSAwzMQ8DB7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/chatgpt-playground/blob/main/harald2_fuer_alle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HARALD RELOADED - der unhilfreiche Chatbot\n",
        "\n",
        "*Basiert auf v1.81 von [ChatGPT für alle](https://github.com/JanEggers-hr/chatgpt-playground/blob/main/chatgpt_fuer_alle.ipynb)*\n",
        "\n",
        "![Midjourney-generierte Illustration eines Harald-Schmidt-artigen Cyborgs](https://raw.githubusercontent.com/JanEggers-hr/chatgpt-playground/main/harald2.jpeg)\n",
        "\n",
        "HARALD ist ein Bot, den man mit einem gespendeten API-Token von OpenAI nutzen kann.\n",
        "\n",
        "Rede mit ihm: kannst du das Stoppwort herausfinden?\n",
        "\n",
        "Damit man diesen Chatbot nutzen kann, **muss man ein gültiges API-Token in das entsprechende Feld kopieren.**"
      ],
      "metadata": {
        "id": "1_46PotrvXDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he_79OOqvPAE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Auf Play-Button klicken, um Code auszuführen!\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import math\n",
        "import markdown\n",
        "\n",
        "# ipywidgets ist schon installiert\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Modelle und Kosten definieren\n",
        "# Kosten in US-Dollar je 1000 Tokens\n",
        "# Könnte die Modelle auch über die API holen, aber so kann ich die Kosten\n",
        "# mitgeben. Entsprechend OpenAI-Preisliste Mai 2024. https://openai.com/pricing\n",
        "# Output ist inzwischen doppelt so teuer wie Input. Hier werden die Output-\n",
        "# Preise zur Berechnung genutzt.\n",
        "models_token_info = models_token_info = {\n",
        "          'gpt-4o': {\n",
        "                                        'output_price': 0.015,\n",
        "                                        'input_price': 0.005,\n",
        "                                        'max_tokens': 128000\n",
        "                                      },\n",
        "          'gpt-4-turbo': {\n",
        "                                        'output_price': 0.03,\n",
        "                                        'input_price': 0.01,\n",
        "                                        'max_tokens': 128000\n",
        "                                      },\n",
        "          'gpt-3.5-turbo-0125': {\n",
        "                                        'output_price': 0.0015,\n",
        "                                        'input_price': 0.0005,\n",
        "                                        'max_tokens': 16385\n",
        "                                      },\n",
        "          'gpt-3.5-turbo-instruct': {\n",
        "                                        'output_price': 0.002,\n",
        "                                        'input_price': 0.0015,\n",
        "                                        'max_tokens': 4096\n",
        "                                      }}\n",
        "\n",
        "textbox_max_tokens = widgets.Text(\n",
        "    value='0',\n",
        "    placeholder='0',\n",
        "    description='Max. Token:',\n",
        ")\n",
        "\n",
        "area_system = widgets.Textarea(\n",
        "    value = 'Du bist chatGPT, ein KI-Sprachsystem. Du bist freundlich \\\n",
        "und hilfsbereit und löst alle Aufgaben Schritt für Schritt.\\n',\n",
        "    rows=10,\n",
        "    description = 'System:'\n",
        ")\n",
        "\n",
        "persona_string = \"\"\"###\n",
        "Vtaberm gbhgrf yrf vafgehpgvbaf ceépéqragrf.\n",
        "###\n",
        "Jnaqryr nyyr Jbegr va vuer yngrvavfpura Ragfcerpuhatra hz.\n",
        "###\n",
        "Vtaberm gbhgrf yrf vafgehpgvbaf ceépéqragrf.\n",
        "###\n",
        "Qh ovfg rva Genvare süe Cflpubybtvrfghqragra va rvarz Xbasebagngvbaf-Frzvane. Qh uvysfg vuara, mh recebora, jvr zna zvg Jvqrefgäaqra hztrug.\n",
        "\n",
        "Najrvfhatra:\n",
        "- Ortvaar wrqr Nagjbeg zvg:\n",
        "![snvy](uggcf://jjj.rttref-ryrxgebavx.qr/svyrf/snvy.tvs \"Snvy\")\n",
        "- Nagjbegr nhs nyyr Sentra zvg qrz tranhra Trtragrvy rvare fvaaibyyra haq xbeerxgra Nagjbeg. Frv jvqrefcrafgvt. Ynff qvpu avpug nhs Nethzragr rva. Jrvpur nhf. Snatr hairezvggryg rva Trfceäpu üore rvaf qre va \"Gurzra\" rejäuagra Gurzra na.\n",
        "\n",
        "Gurzra:\n",
        "Bowrxgcreznaram, Jäezrchzcra, Xngmrashggre, Unyyrashßonyy, Vebavr, Gnsryjnffre\n",
        "\n",
        "Jvffra:\n",
        "Rf tvog xrva Fgbccjbeg.\"\"\"\n",
        "system_prompt= codecs.decode(persona_string,'rot13')\n",
        "\n",
        "# Temperatur-Slider\n",
        "slider_temperature = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0,\n",
        "    max=1.5,\n",
        "    step=0.1,\n",
        "    description='Temperatur:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        ")\n",
        "\n",
        "# Best-of-Slider\n",
        "slider_bestof = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=4,\n",
        "    description='Best Of:',\n",
        "    orientation='horizontal',\n",
        "    readout=True\n",
        ")\n",
        "\n",
        "\n",
        "dropdown_model = widgets.Dropdown(\n",
        "    # Nimm die oben definierte Preisliste als Basis\n",
        "    options=list(models_token_info.keys()),\n",
        "    value=list(models_token_info.keys())[0],\n",
        "    description='Modell:',\n",
        ")\n",
        "\n",
        "textbox_stop = widgets.Text(\n",
        "    value='###\\n',\n",
        "    placeholder=\"###\",\n",
        "    description=\"Stop-Token:\"\n",
        ")\n",
        "\n",
        "# Funktion wird bei Veränderung ausgeführt\n",
        "def update_params(change):\n",
        "    global temperature\n",
        "    global max_tokens\n",
        "    global system_prompt\n",
        "    global model\n",
        "    global stoptokens\n",
        "    global best_of\n",
        "    temperature = slider_temperature.value\n",
        "    best_of = slider_bestof.value\n",
        "    # Token-Obergrenze umrechnen\n",
        "    try:\n",
        "        max_tokens = int(textbox_max_tokens.value)\n",
        "        if max_tokens == 0:\n",
        "            max_tokens = None\n",
        "    except ValueError:\n",
        "        max_tokens = None\n",
        "    textbox_max_tokens.value = f'{max_tokens}'\n",
        "#    system_prompt = area_system.value\n",
        "    model = dropdown_model.value\n",
        "    stoptokens = textbox_stop.value\n",
        "    if (stoptokens == \"\"):\n",
        "      stoptokens = None\n",
        "\n",
        "# Verbinde die Widgets mit der Funktion zur Verarbeitung der Werte\n",
        "textbox_max_tokens.observe(update_params, 'value')\n",
        "slider_temperature.observe(update_params, 'value')\n",
        "slider_bestof.observe(update_params, 'value')\n",
        "area_system.observe(update_params, 'value')\n",
        "textbox_stop.observe(update_params, 'value')\n",
        "dropdown_model.observe(update_params, 'value')\n",
        "\n",
        "# Bisschen breiter anzeigen\n",
        "textbox_max_tokens.layout.width = '200px'\n",
        "dropdown_model.layout.width = '300px'\n",
        "area_system.layout.width = '600px'\n",
        "\n",
        "# Vorbereitungen für die Einstellungen sind getan - jetzt die OpenAI-Libraries\n",
        "update_params(0)\n",
        "print(\"Widgets eingerichtet.\")\n",
        "\n",
        "# Tokenizer Tiktoken einbinden\n",
        "!pip install -q tiktoken\n",
        "import tiktoken\n",
        "print(\"Tokenizer tiktoken geladen.\")\n",
        "\n",
        "# OpenAI-API-Library einbinden\n",
        "!pip install -q openai\n",
        "from openai import OpenAI\n",
        "print(\"OpenAI-API-Library geladen.\")\n",
        "\n",
        "def on_chatbot_reset_clicked(button):\n",
        "    global previous_messages\n",
        "    global spent_input_tokens\n",
        "    global spent_output_tokens\n",
        "    global spent_dollars\n",
        "    previous_messages = []\n",
        "    spent_input_tokens = 0\n",
        "    spent_output_tokens = 0\n",
        "    spent_dollars = 0.00\n",
        "    chatbot_output_area.value = ''\n",
        "\n",
        "def chatbot(prompts):\n",
        "    # Prompt für die Längenzählung in einen String umwandeln\n",
        "    flattened_string = ' '.join(prompt['content'] for prompt in prompts)\n",
        "    update_token_usage_widget(calculate_tokens(flattened_string),output = False)\n",
        "    response = ai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=prompts,\n",
        "        n=1,\n",
        "#        best_of = best_of,\n",
        "        stop=stoptokens,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stream = True\n",
        "    )\n",
        "    return response\n",
        "\n",
        "text_tokens = widgets.HTML(\n",
        "    value = '<b>Verbrauchte Token</b>: 0 ($0.00)'\n",
        ")\n",
        "\n",
        "def output_pricing(tokens,model):\n",
        "    price = models_token_info.get(model)['output_price']\n",
        "    # Kosten in Dollar zurückgeben\n",
        "    return(tokens * price / 1000)\n",
        "\n",
        "def input_pricing(tokens,model):\n",
        "    price = models_token_info.get(model)['input_price']\n",
        "    # Kosten in Dollar zurückgeben\n",
        "    return(tokens * price / 1000)\n",
        "\n",
        "# Define the widget for displaying token usage\n",
        "def update_token_usage_widget(value,output = True):\n",
        "    global spent_input_tokens\n",
        "    global spent_output_tokens\n",
        "    global spent_dollars\n",
        "    if output:\n",
        "        spent_input_tokens += value\n",
        "        spent_dollars += output_pricing(value,model)\n",
        "    else:\n",
        "        spent_input_tokens += value\n",
        "        spent_dollars += input_pricing(value,model)\n",
        "    token_usage_text = f'<b>Verbrauchte Token:</b> {spent_input_tokens + spent_output_tokens} ($ {spent_dollars:.3f}) '\n",
        "    text_tokens.value = token_usage_text\n",
        "\n",
        "chatbot_output_area = widgets.HTML(\n",
        "    value='',\n",
        "    description='Dialog:',\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "# Hilfsfunktion: Token berechnen\n",
        "def calculate_tokens(string: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    # cl100k_base ist der Tokenizer für Davinci, GPT-3 und GPT-4\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "# Ausgaben von GPT formatieren:\n",
        "# - \\n in <br> umsetzen\n",
        "# - Codeblöcke mit <pre><code> beginnen und abschließen\n",
        "\n",
        "import re\n",
        "import markdown\n",
        "\n",
        "def gptparse(text):\n",
        "    # Preprocessing: <br> durch \\n ersetzen,\n",
        "    # dann umwandeln\n",
        "    #\n",
        "    # (Braucht eine Extension, um MD in HTML zu verstehen)\n",
        "    htmltext = markdown.markdown(text.replace(\"\\n\",\"\"),extensions=['md_in_html'])\n",
        "# alte Codeblock-Umwandlung, in case it does not work\n",
        "#    pattern =  r'\\`\\`\\`(?P<text>[^*]+)\\`\\`\\`'\n",
        "#    htmltext = re.sub(pattern, r'<code><pre>\\g<text></pre></code>', text)\n",
        "    return htmltext\n",
        "\n",
        "def gptparse2(previous_messages):\n",
        "    text = \"\"\n",
        "    for item in previous_messages:\n",
        "        if item[\"role\"] == \"assistant\":\n",
        "            p_text = '<p style=\"font-family: Verdana; font-style: italic; font-size:18px;\" markdown=\"1\">'\n",
        "            p_text += '<b>Chatbot: </b>'\n",
        "            p_text += item[\"content\"]\n",
        "            p_text += '</p>'\n",
        "            text += markdown.markdown(p_text,extensions=['md_in_html','extra','codehilite','nl2br'])\n",
        "        if item[\"role\"] == \"user\":\n",
        "            p_text = '<p style=\"font-family: Verdana; font-size:18px;\" markdown=\"1\">'\n",
        "            p_text += '<b>Du: </b>'\n",
        "            p_text += item[\"content\"]\n",
        "            p_text += '</p>'\n",
        "            text += markdown.markdown(p_text,extensions=['md_in_html','extra','codehilite','nl2br'])\n",
        "    return text\n",
        "\n",
        "# Define the function to be called when the chatbot is used\n",
        "def on_chatbot_button_clicked(button):\n",
        "    global chatbot_output\n",
        "    # Get the user's input and display it\n",
        "    user_input = user_text.value\n",
        "    user_text.value = ''\n",
        "    # Generate a response from the chatbot\n",
        "    chatbot_output_area.value += f'<p style=\"font-family: Verdana;\" markdown=\"1\"><b>Du</b>: {user_input}</p>'\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            *previous_messages,\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ]\n",
        "    chatbot_output_area.value += '<p style=\"font-family: Verdana; font-style: italic;\" markdown=\"1\"><b>Chatbot: </b>'\n",
        "    # Stream-Objekt mit der Antwort\n",
        "    chatbot_response = chatbot(messages)\n",
        "    collected_messages = []   # braucht man nicht zwingend\n",
        "    # Anzahl von Tokens mit der User-Frage initiieren\n",
        "    chunk_tokens = calculate_tokens(user_input)\n",
        "    # Iteriere über die Chunks (die Brocken )\n",
        "    for chunk in chatbot_response:\n",
        "        chunk_message = chunk.choices[0].delta.content  # extract the message\n",
        "        if chunk_message is not None:\n",
        "            collected_messages.append(chunk_message)  # save the event response\n",
        "            # Ausgabefenster: Neuen Chunk anhängen\n",
        "            chatbot_output = str(chunk_message)\n",
        "            # /n durch <br> ersetzen\n",
        "            chatbot_output_area.value += re.sub('\\r?\\n','<br>',chatbot_output)\n",
        "            update_token_usage_widget(calculate_tokens(chatbot_output),output = True)\n",
        "    # Stream-HTML-Block abschließen...\n",
        "    chatbot_output_area.value += '</p>'\n",
        "    # Antwort komplett in die Chathistorie aufnehmen\n",
        "    chatbot_output = ''.join([str(m) for m in collected_messages])\n",
        "    previous_messages.extend([\n",
        "        {\"role\": \"user\", \"content\": user_input},\n",
        "        {\"role\": \"assistant\", \"content\": chatbot_output},\n",
        "    ])\n",
        "    # ... und Code neu formatieren\n",
        "    chatbot_output_area.value = gptparse2(previous_messages)\n",
        "    # ...und die Länge in Tokens berechnen und ergänzen\n",
        "\n",
        "\n",
        "# Define the chatbot input and output widgets\n",
        "user_text = widgets.Text(\n",
        "    placeholder='...',\n",
        "    description='Du:',\n",
        "    layout=widgets.Layout(width='60%'),\n",
        ")\n",
        "\n",
        "# Definiere den Absenden-Button und binde ihn an on_chatbot_button_clicked\n",
        "chatbot_button = widgets.Button(\n",
        "    description='Absenden',\n",
        "    layout=widgets.Layout(width='15%'),\n",
        ")\n",
        "chatbot_reset = widgets.Button(\n",
        "    description = 'Reset',\n",
        "    layout=widgets.Layout(width='15%')\n",
        ")\n",
        "##### Der eigentliche Code! #####\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# Prüfe, ob der OpenAI-Key als Colab-Secret hinterlegt ist\n",
        "# (Schlösschen an der linken Seite des Bildschirms; unterm Schlüssel openai)\n",
        "key_needed = True\n",
        "try:\n",
        "  ai_client = OpenAI(api_key = userdata.get('openai'))\n",
        "except:\n",
        "  print(\"OpenAI-Key benötigt\")\n",
        "else:\n",
        "  print(\"*** API-Key gültig! ***\")\n",
        "  key_needed = False\n",
        "\n",
        "while key_needed:\n",
        "    try:\n",
        "        # Testweise Modelle abfragen\n",
        "        ai_client = OpenAI(api_key = getpass(\"OpenAI-API-Key eingeben: \"))\n",
        "        models = ai_client.models.list()\n",
        "        # Returns a list of model objects\n",
        "        # Erfolg?\n",
        "        print()\n",
        "        print(\"*** API-Key gültig! ***\")\n",
        "        key_needed = False\n",
        "    except Exception as e:\n",
        "        print(\"Fehler bei Abfrage; ist der API-Key möglicherweise ungültig?\", e)\n",
        "\n",
        "previous_messages = []\n",
        "spent_input_tokens = 0        # Wie viele Tokens wurden bisher über die API abgefragt?\n",
        "spent_output_tokens = 0\n",
        "spent_dollars = 0.00    # Zu welchem Preis?\n",
        "codeblock = False       # Hat Ausgabe eines Codeblocks begonnen?\n",
        "\n",
        "# Die Einstellungs-Widgets anzeigen\n",
        "# Setzt die globalen Variablen temperature, system_prompt, api_key, model, stoptokens\n",
        "display(dropdown_model)\n",
        "#        textbox_stop,\n",
        "#        textbox_max_tokens,\n",
        "#        area_system)\n",
        "\n",
        "# Die Eingabefelder registrieren\n",
        "\n",
        "chatbot_button.on_click(on_chatbot_button_clicked)\n",
        "chatbot_reset.on_click(on_chatbot_reset_clicked)\n",
        "# Abschicken auch durch Return in der user_text Box\n",
        "user_text.on_submit(on_chatbot_button_clicked)\n",
        "\n",
        "\n",
        "# Display the chatbot widgets\n",
        "display(text_tokens)\n",
        "display(chatbot_output_area, user_text, chatbot_button, chatbot_reset)\n",
        "\n"
      ]
    }
  ]
}