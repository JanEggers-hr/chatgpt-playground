{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "history_visible": true,
      "authorship_tag": "ABX9TyOfki+oVZvnTF4L9vUfr95z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/chatgpt-playground/blob/main/Sprich_v01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPRICH\n",
        "\n",
        "*v0.1beta* - Ein KI-Chatbot, der den erzeugten Text mit der Open-Source-Bibliothek \"Bark\" vorliest\n",
        "\n",
        "## Colabs am Leben halten\n",
        "\n",
        "Es wird empfohlen, eine Browser-Erweiterung wie den [Colab Automatic Clicker](https://addons.mozilla.org/en-US/firefox/addon/colab-automatic-clicker/) oder [Colab Auto Reconnect (Chrome)](https://chrome.google.com/webstore/detail/colab-auto-reconnect/ifilpgffgdbhafnaebocnofaehicbkem) zu nutzen, damit die Colab-Session offen bleibt.\n",
        "\n",
        "## Vorbereitungen\n",
        "\n",
        "***Bitte einmal kurz auf den Play-Button unter der nächsten Zelle klicken, um den Sprachgenerator zu laden - das dauert etwa 3-4 Minuten.***"
      ],
      "metadata": {
        "id": "1_46PotrvXDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he_79OOqvPAE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title BARK-Sprachgenerator importieren\n",
        "\n",
        "\n",
        "# https://github.com/py-pdf/benchmarks\n",
        "!pip install -q pypdfium2\n",
        "import pypdfium2 as pdfium\n",
        "print(\"PDF-Importer pypdfium geladen.\")\n",
        "\n",
        "# install bark as well as pytorch nightly to get blazing fast flash-attention\n",
        "print(\"Text-to-speech-Bibliothek Bark installieren - das dauert...\")\n",
        "!pip install -q git+https://github.com/suno-ai/bark.git && \\\n",
        "pip uninstall -y torch torchvision torchaudio && \\\n",
        "pip install -q --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
        "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
        "from IPython.display import Audio\n",
        "\n",
        "preload_models()\n",
        "print(\"Audio-Generator Bark geladen.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Einstellungen für das Modell\n",
        "\n",
        "Basiseinstellungen: Temperatur (tendenziell niedriger als sonst, um reproduzierbare Ergebnisse zu bekommen), Modell, Stop-Token (der Text des PDF wird in Stop-Token eingefasst, um dem Modell eine Sinneinheit zu signalisieren), und das System-Prompt (die Aufgabenbeschreibung)."
      ],
      "metadata": {
        "id": "jAzbYAnDrR37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ChatGPT für alle - Ausführen: Klick auf den \"Play\"-Button\n",
        "import requests\n",
        "import json\n",
        "import math\n",
        "import markdown\n",
        "\n",
        "# ipywidgets ist schon installiert\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "voices_info = [('0: Sirilexa, flach, künstlich',0),\n",
        "               ('1: Katleen, frisch, etwas verhallt', 1),\n",
        "               ('2: Rico, professionell, Ende 30', 2),\n",
        "               ('3: Telefon-Tina, Frau Mitte 40, kratzig', 3),\n",
        "               ('4: Atmo-Anne, Ende 20, mit Atmo', 4),\n",
        "               ('5: Klaus, Anfang 40, lebendig, künstlerisch', 5),\n",
        "               ('6: Daniel, leicht österreichischer Einschlag', 6),\n",
        "               ('7: Mad Rajav, Sprecher, der viel äääh sagt', 7),\n",
        "               ('8: Basti, guter Werbesprecher',8),\n",
        "               ('9: Theo, schlechter Werbesprecher',9)]\n",
        "\n",
        "\n",
        "dropdown_voice = widgets.Dropdown(\n",
        "    # Nimm die oben definierte Preisliste als Basis\n",
        "    options=voices_info,\n",
        "    value=5,\n",
        "    description='Stimme:',\n",
        ")\n",
        "# Modelle und Kosten definieren\n",
        "# Kosten in US-Dollar je 1000 Tokens\n",
        "models_token_info = {'gpt-3.5-turbo': {\n",
        "                                        'pricing': 0.002,\n",
        "                                        'max_tokens': 4096\n",
        "                                      },\n",
        "          'gpt-4': {\n",
        "                                        'pricing': 0.03,\n",
        "                                        'max_tokens': 8192\n",
        "                                      },\n",
        "          'gpt-4-32k': {\n",
        "                                        'pricing': 0.06,\n",
        "                                        'max_tokens': 32768\n",
        "                                      }}\n",
        "\n",
        "textbox_max_tokens = widgets.Text(\n",
        "    value='0',\n",
        "    placeholder='0',\n",
        "    description='Max. Token:',\n",
        ")\n",
        "\n",
        "area_system = widgets.Textarea(\n",
        "    value = 'Du bist Kim, eine Radiomoderatorin in einem Sender in einer kleinen Stadt. Du kündigst jeden Musiktitel mit zwei oder drei Sätzen an, die dir persönlich dazu einfallen.',\n",
        "    rows=10,\n",
        "    description = 'System:'\n",
        ")\n",
        "\n",
        "# Temperatur-Slider\n",
        "slider_temperature = widgets.FloatSlider(\n",
        "    value=0.7,\n",
        "    min=0,\n",
        "    max=1,\n",
        "    step=0.1,\n",
        "    description='Temperatur:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        ")\n",
        "\n",
        "# Best-of-Slider\n",
        "slider_bestof = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=4,\n",
        "    description='Best Of:',\n",
        "    orientation='horizontal',\n",
        "    readout=True\n",
        ")\n",
        "\n",
        "\n",
        "dropdown_model = widgets.Dropdown(\n",
        "    # Nimm die oben definierte Preisliste als Basis\n",
        "    options=list(models_token_info.keys()),\n",
        "    value=list(models_token_info.keys())[0],\n",
        "    description='Modell:',\n",
        ")\n",
        "\n",
        "textbox_stop = widgets.Text(\n",
        "    value='###\\n',\n",
        "    placeholder=\"###\",\n",
        "    description=\"Stop-Token:\"\n",
        ")\n",
        "\n",
        "# Funktion wird bei Veränderung ausgeführt\n",
        "def update_params(change):\n",
        "    global temperature\n",
        "    global max_tokens\n",
        "    global system_prompt\n",
        "    global model\n",
        "    global stoptokens\n",
        "    global best_of\n",
        "    temperature = slider_temperature.value\n",
        "    best_of = slider_bestof.value\n",
        "    # Token-Obergrenze umrechnen\n",
        "    try:\n",
        "        max_tokens = int(textbox_max_tokens.value)\n",
        "        if max_tokens == 0:\n",
        "            max_tokens = None\n",
        "    except ValueError:\n",
        "        max_tokens = None\n",
        "    textbox_max_tokens.value = f'{max_tokens}'\n",
        "    system_prompt = area_system.value\n",
        "    model = dropdown_model.value\n",
        "    stoptokens = textbox_stop.value\n",
        "    if (stoptokens == \"\"):\n",
        "      stoptokens = None\n",
        "\n",
        "# Verbinde die Widgets mit der Funktion zur Verarbeitung der Werte\n",
        "textbox_max_tokens.observe(update_params, 'value')\n",
        "slider_temperature.observe(update_params, 'value')\n",
        "slider_bestof.observe(update_params, 'value')\n",
        "area_system.observe(update_params, 'value')\n",
        "textbox_stop.observe(update_params, 'value')\n",
        "dropdown_model.observe(update_params, 'value')\n",
        "\n",
        "# Bisschen breiter anzeigen\n",
        "textbox_max_tokens.layout.width = '200px'\n",
        "dropdown_model.layout.width = '300px'\n",
        "area_system.layout.width = '600px'\n",
        "\n",
        "# Vorbereitungen für die Einstellungen sind getan - jetzt die OpenAI-Libraries\n",
        "update_params(0)\n",
        "print(\"Widgets eingerichtet.\")\n",
        "\n",
        "# Tokenizer Tiktoken einbinden\n",
        "!pip install -q tiktoken\n",
        "import tiktoken\n",
        "print(\"Tokenizer tiktoken geladen.\")\n",
        "\n",
        "# OpenAI-API-Library einbinden\n",
        "!pip install -q openai\n",
        "import openai\n",
        "print(\"OpenAI-API-Library geladen.\")\n",
        "\n",
        "def on_chatbot_reset_clicked(button):\n",
        "    global previous_messages\n",
        "    global spent_tokens\n",
        "    global spent_dollars\n",
        "    previous_messages = []\n",
        "    spent_tokens = 0\n",
        "    spent_dollars = 0.00\n",
        "    chatbot_output_area.value = ''\n",
        "\n",
        "def chatbot(prompts):\n",
        "    # Prompt\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=prompts,\n",
        "        n=1,\n",
        "#        best_of = best_of,\n",
        "        stop=stoptokens,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stream = True\n",
        "    )\n",
        "    return response\n",
        "\n",
        "text_tokens = widgets.HTML(\n",
        "    value = '<b>Verbrauchte Token</b>: 0 ($0.00)'\n",
        ")\n",
        "\n",
        "# Define the widget for displaying token usage\n",
        "def update_token_usage_widget(value):\n",
        "    global spent_tokens\n",
        "    global spent_dollars\n",
        "    spent_tokens += value\n",
        "    spent_dollars += pricing(value)\n",
        "\n",
        "    token_usage_text = f'<b>Verbrauchte Token:</b> {spent_tokens} ($ {spent_dollars:.3f}) '\n",
        "    text_tokens.value = token_usage_text\n",
        "\n",
        "chatbot_output_area = widgets.HTML(\n",
        "    value='',\n",
        "    description='Dialog:',\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "# Hilfsfunktion: Token berechnen\n",
        "def calculate_tokens(string: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    # cl100k_base ist der Tokenizer für Davinci, GPT-3 und GPT-4\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "# Ausgaben von GPT formatieren:\n",
        "# - \\n in <br> umsetzen\n",
        "# - Codeblöcke mit <pre><code> beginnen und abschließen\n",
        "\n",
        "import re\n",
        "import markdown\n",
        "\n",
        "def gptparse(text):\n",
        "    # Preprocessing: <br> durch \\n ersetzen,\n",
        "    # dann umwandeln\n",
        "    #\n",
        "    # (Braucht eine Extension, um MD in HTML zu verstehen)\n",
        "    htmltext = markdown.markdown(text.replace(\"\\n\",\"\"),extensions=['md_in_html'])\n",
        "# alte Codeblock-Umwandlung, in case it does not work\n",
        "#    pattern =  r'\\`\\`\\`(?P<text>[^*]+)\\`\\`\\`'\n",
        "#    htmltext = re.sub(pattern, r'<code><pre>\\g<text></pre></code>', text)\n",
        "    return htmltext\n",
        "\n",
        "def gptparse2(previous_messages):\n",
        "    text = \"\"\n",
        "    for item in previous_messages:\n",
        "        if item[\"role\"] == \"assistant\":\n",
        "            p_text = '<p style=\"font-family: Verdana; font-style: italic;\" markdown=\"1\">'\n",
        "            p_text += '<b>Chatbot: </b>'\n",
        "            p_text += item[\"content\"]\n",
        "            p_text += '</p>'\n",
        "            text += markdown.markdown(p_text,extensions=['md_in_html','extra','codehilite','nl2br'])\n",
        "        if item[\"role\"] == \"user\":\n",
        "            p_text = '<p style=\"font-family: Verdana;\" markdown=\"1\">'\n",
        "            p_text += '<b>Du: </b>'\n",
        "            p_text += item[\"content\"]\n",
        "            p_text += '</p>'\n",
        "            text += markdown.markdown(p_text,extensions=['md_in_html','extra','codehilite','nl2br'])\n",
        "    return text\n",
        "\n",
        "# Define the function to be called when the chatbot is used\n",
        "def on_chatbot_button_clicked(button):\n",
        "    global chatbot_output\n",
        "    # Get the user's input and display it\n",
        "    user_input = user_text.value\n",
        "    user_text.value = ''\n",
        "    # Generate a response from the chatbot\n",
        "    chatbot_output_area.value += f'<p style=\"font-family: Verdana;\" markdown=\"1\"><b>Du</b>: {user_input}</p>'\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            *previous_messages,\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ]\n",
        "    chatbot_output_area.value += '<p style=\"font-family: Verdana; font-style: italic;\" markdown=\"1\"><b>Chatbot: </b>'\n",
        "    # Stream-Objekt mit der Antwort\n",
        "    chatbot_response = chatbot(messages)\n",
        "    collected_messages = []   # braucht man nicht zwingend\n",
        "    # Anzahl von Tokens mit der User-Frage initiieren\n",
        "    chunk_tokens = calculate_tokens(user_input)\n",
        "    # Iteriere über die Chunks (die Brocken )\n",
        "    for chunk in chatbot_response:\n",
        "        chunk_message = chunk['choices'][0]['delta']  # extract the message\n",
        "        collected_messages.append(chunk_message)  # save the event response\n",
        "        # Ausgabefenster: Neuen Chunk anhängen\n",
        "        chatbot_output = chunk_message.get('content', '')\n",
        "        # /n durch <br> ersetzen\n",
        "        chatbot_output_area.value += re.sub('\\r?\\n','<br>',chatbot_output)\n",
        "        update_token_usage_widget(calculate_tokens(chatbot_output))\n",
        "    # Stream-HTML-Block abschließen...\n",
        "    chatbot_output_area.value += '</p>'\n",
        "    # Antwort komplett in die Chathistorie aufnehmen\n",
        "    chatbot_output = ''.join([m.get('content', '') for m in collected_messages])\n",
        "    # Audio-Ausgabe\n",
        "    speaker = f\"de_speaker_{dropdown_voice.value}\"\n",
        "    audio_array = generate_audio(chatbot_output,history_prompt=speaker)\n",
        "    audio_widget = Audio(audio_array, rate=SAMPLE_RATE,autoplay = True)\n",
        "    display(audio_widget)\n",
        "    previous_messages.extend([\n",
        "        {\"role\": \"user\", \"content\": user_input},\n",
        "        {\"role\": \"assistant\", \"content\": chatbot_output},\n",
        "    ])\n",
        "    # ... und Code neu formatieren\n",
        "    chatbot_output_area.value = gptparse2(previous_messages)\n",
        "    # ...und die Länge in Tokens berechnen und ergänzen\n",
        "\n",
        "def pricing(tokens):\n",
        "    price = models_token_info.get(model)['pricing']\n",
        "    # Kosten in Dollar zurückgeben\n",
        "    return(tokens * price / 1000)\n",
        "\n",
        "\n",
        "# Define the chatbot input and output widgets\n",
        "user_text = widgets.Text(\n",
        "    placeholder='...',\n",
        "    description='Du:',\n",
        "    layout=widgets.Layout(width='60%'),\n",
        ")\n",
        "\n",
        "# Definiere den Absenden-Button und binde ihn an on_chatbot_button_clicked\n",
        "chatbot_button = widgets.Button(\n",
        "    description='Absenden',\n",
        "    layout=widgets.Layout(width='15%'),\n",
        ")\n",
        "chatbot_reset = widgets.Button(\n",
        "    description = 'Reset',\n",
        "    layout=widgets.Layout(width='15%')\n",
        ")\n",
        "##### Der eigentliche Code! #####\n",
        "\n",
        "from getpass import getpass\n",
        "key_needed = True\n",
        "while key_needed:\n",
        "    openai.api_key = getpass(\"OpenAI-API-Key eingeben: \")\n",
        "    try:\n",
        "        # Testweise Modelle abfragen\n",
        "        models = openai.Model.list()['data']\n",
        "        # Erfolg?\n",
        "        print(\"API-Key gültig!\")\n",
        "        key_needed = False\n",
        "    except:\n",
        "        print(\"Fehler bei Abfrage; ist der API-Key möglicherweise ungültig?\")\n",
        "previous_messages = []\n",
        "spent_tokens = 0        # Wie viele Tokens wurden bisher über die API abgefragt?\n",
        "spent_dollars = 0.00    # Zu welchem Preis?\n",
        "codeblock = False       # Hat Ausgabe eines Codeblocks begonnen?\n",
        "\n",
        "# Die Einstellungs-Widgets anzeigen\n",
        "# Setzt die globalen Variablen temperature, system_prompt, api_key, model, stoptokens\n",
        "display(slider_temperature,\n",
        "#        slider_bestof,\n",
        "        dropdown_model,\n",
        "        textbox_stop,\n",
        "        textbox_max_tokens,\n",
        "        area_system)\n",
        "\n",
        "# Die Eingabefelder registrieren\n",
        "\n",
        "chatbot_button.on_click(on_chatbot_button_clicked)\n",
        "chatbot_reset.on_click(on_chatbot_reset_clicked)\n",
        "# Abschicken auch durch Return in der user_text Box\n",
        "user_text.on_submit(on_chatbot_button_clicked)\n",
        "\n",
        "\n",
        "# Display the chatbot widgets\n",
        "display(dropdown_voice)\n",
        "display(text_tokens)\n",
        "display(chatbot_output_area, user_text, chatbot_button, chatbot_reset)\n",
        "\n"
      ],
      "metadata": {
        "id": "4z2rV5r0nTna",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bekannte Probleme\n",
        "\n",
        "- Manchmal verschluckt das Eingabefeld die letzten 1, 2 Zeichen\n"
      ],
      "metadata": {
        "id": "YIoVYGxYmQcz"
      }
    }
  ]
}