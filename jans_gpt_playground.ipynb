{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeBtNb+FhWqLGq4LpJopDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/chatgpt-playground/blob/main/jans_gpt_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chatGPT for the rest of us! (English Version)\n",
        "\n",
        "*v1.4* - A Colab notebook for chatting with the GPT large language models, offering the additional settings from the playground All you need is an API token.\n",
        "\n",
        "## How to use this\n",
        "\n",
        "If you are still on Github right now, click the \"Open in Colab\" Button top left - this copies the code to a Google Colab virtual environment. Which is a computer in the cloud **where Google allows you to run simple Python programs free of charge**. (You will need to login with some kind of Google ID, be it GMail, Android, or Youtube.\n",
        "\n",
        "All there is to do: Click the small \"play\" button symbol below these paragraphs to run the code, wait for it to load the first batch of programs, then copy an API token into the slot.\n",
        "\n",
        "To avoid losing the connection to the Colab environment, I recommend using [Colab Automatic Clicker (Firefox)](https://addons.mozilla.org/en-US/firefox/addon/colab-automatic-clicker/) or[Colab Auto Reconnect (Chrome)](https://chrome.google.com/webstore/detail/colab-auto-reconnect/ifilpgffgdbhafnaebocnofaehicbkem)\n",
        "\n",
        "## The Chatbot\n",
        "\n",
        "You may adjust these parameters:\n",
        "- **Temperature** controls the amount of chance the model allows when selecting the next tokens to answer.\n",
        "- **Model** determins which language model you use. GPT3.5 is the cheaper standard model, GPT-4 ist the most powerful model at the time being. GPT-4 32k is for very long input contexts (up to approx. 25.000 words).\n",
        "- **Stop Token** is used to structure sample input. Start with a prompt, then a stop token, then a query-answer pair, then another stop token, then another query-answer pair.\n",
        "- **Max-Token** makes the model stop after generating these tokens. Set it very low if you want to get short answert like Yes or No.\n",
        "- **System** is the bot's personality; the way it is supposed to behave. Bots may escape the instructions in their system prompt, especially GPT3.5.\n",
        "\n",
        "\n",
        "If you wish to use the chatbot, **you will need to copy a valid OpenAI API token code into the window when prompted.**\n",
        "\n",
        "\n",
        "## Click the play symbol below to run the code!"
      ],
      "metadata": {
        "id": "1_46PotrvXDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he_79OOqvPAE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import requests\n",
        "import json\n",
        "import math\n",
        "import markdown\n",
        "\n",
        "# ipywidgets ist schon installiert\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Modelle und Kosten definieren\n",
        "# Kosten in US-Dollar je 1000 Tokens\n",
        "models_token_info = {'gpt-3.5-turbo': {\n",
        "                                        'pricing': 0.002,\n",
        "                                        'max_tokens': 4096\n",
        "                                      },\n",
        "          'gpt-4': {\n",
        "                                        'pricing': 0.03,\n",
        "                                        'max_tokens': 8192\n",
        "                                      },\n",
        "          'gpt-4-32k': {\n",
        "                                        'pricing': 0.06,\n",
        "                                        'max_tokens': 32768\n",
        "                                      }}\n",
        "\n",
        "textbox_max_tokens = widgets.Text(\n",
        "    value='0',\n",
        "    placeholder='0',\n",
        "    description='Max. Token:',\n",
        ")\n",
        "\n",
        "area_system = widgets.Textarea(\n",
        "    value = 'You are ChatGPT, a helpful AI assistant. \\\n",
        "You try to solve every tasp presented to you, proceeding step by step.\\n',\n",
        "    rows=10,\n",
        "    description = 'System:'\n",
        ")\n",
        "\n",
        "# Temperatur-Slider\n",
        "slider_temperature = widgets.FloatSlider(\n",
        "    value=0.7,\n",
        "    min=0,\n",
        "    max=1,\n",
        "    step=0.1,\n",
        "    description='Temperature:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        ")\n",
        "\n",
        "# Best-of-Slider\n",
        "slider_bestof = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=4,\n",
        "    description='Best Of:',\n",
        "    orientation='horizontal',\n",
        "    readout=True\n",
        ")\n",
        "\n",
        "\n",
        "dropdown_model = widgets.Dropdown(\n",
        "    # Nimm die oben definierte Preisliste als Basis\n",
        "    options=list(models_token_info.keys()),\n",
        "    value=list(models_token_info.keys())[0],\n",
        "    description='Model:',\n",
        ")\n",
        "\n",
        "textbox_stop = widgets.Text(\n",
        "    value='###\\n',\n",
        "    placeholder=\"###\",\n",
        "    description=\"Stop Token:\"\n",
        ")\n",
        "\n",
        "# Funktion wird bei Veränderung ausgeführt\n",
        "def update_params(change):\n",
        "    global temperature\n",
        "    global max_tokens\n",
        "    global system_prompt\n",
        "    global model\n",
        "    global stoptokens\n",
        "    global best_of\n",
        "    temperature = slider_temperature.value\n",
        "    best_of = slider_bestof.value\n",
        "    # Token-Obergrenze umrechnen\n",
        "    try:\n",
        "        max_tokens = int(textbox_max_tokens.value)\n",
        "        if max_tokens == 0:\n",
        "            max_tokens = None\n",
        "    except ValueError:\n",
        "        max_tokens = None\n",
        "    textbox_max_tokens.value = f'{max_tokens}'\n",
        "    system_prompt = area_system.value\n",
        "    model = dropdown_model.value\n",
        "    stoptokens = textbox_stop.value\n",
        "    if (stoptokens == \"\"):\n",
        "      stoptokens = None\n",
        "\n",
        "# Verbinde die Widgets mit der Funktion zur Verarbeitung der Werte\n",
        "textbox_max_tokens.observe(update_params, 'value')\n",
        "slider_temperature.observe(update_params, 'value')\n",
        "slider_bestof.observe(update_params, 'value')\n",
        "area_system.observe(update_params, 'value')\n",
        "textbox_stop.observe(update_params, 'value')\n",
        "dropdown_model.observe(update_params, 'value')\n",
        "\n",
        "# Bisschen breiter anzeigen\n",
        "textbox_max_tokens.layout.width = '200px'\n",
        "dropdown_model.layout.width = '300px'\n",
        "area_system.layout.width = '600px'\n",
        "\n",
        "# Vorbereitungen für die Einstellungen sind getan - jetzt die OpenAI-Libraries\n",
        "update_params(0)\n",
        "print(\"Widgets generated\")\n",
        "\n",
        "# Tokenizer Tiktoken einbinden\n",
        "!pip install -q tiktoken\n",
        "import tiktoken\n",
        "print(\"Tokenizer tiktoken loaded\")\n",
        "\n",
        "# OpenAI-API-Library einbinden\n",
        "!pip install -q openai\n",
        "import openai\n",
        "print(\"OpenAI-API-Library loaded\")\n",
        "\n",
        "def on_chatbot_reset_clicked(button):\n",
        "    global previous_messages\n",
        "    global spent_tokens\n",
        "    global spent_dollars\n",
        "    previous_messages = []\n",
        "    spent_tokens = 0\n",
        "    spent_dollars = 0.00\n",
        "    chatbot_output_area.value = ''\n",
        "\n",
        "def chatbot(prompts):\n",
        "    # Prompt\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=prompts,\n",
        "        n=1,\n",
        "#        best_of = best_of,\n",
        "        stop=stoptokens,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stream = True\n",
        "    )\n",
        "    return response\n",
        "\n",
        "text_tokens = widgets.HTML(\n",
        "    value = '<b>Tokens used</b>: 0 ($0.00)'\n",
        ")\n",
        "\n",
        "# Define the widget for displaying token usage\n",
        "def update_token_usage_widget(value):\n",
        "    global spent_tokens\n",
        "    global spent_dollars\n",
        "    spent_tokens += value\n",
        "    spent_dollars += pricing(value)\n",
        "\n",
        "    token_usage_text = f'<b>Tokens used</b> {spent_tokens} ($ {spent_dollars:.3f}) '\n",
        "    text_tokens.value = token_usage_text\n",
        "\n",
        "chatbot_output_area = widgets.HTML(\n",
        "    value='',\n",
        "    description='Dialog:',\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "# Hilfsfunktion: Token berechnen\n",
        "def calculate_tokens(string: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    # cl100k_base ist der Tokenizer für Davinci, GPT-3 und GPT-4\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "# Ausgaben von GPT formatieren:\n",
        "# - \\n in <br> umsetzen\n",
        "# - Codeblöcke mit <pre><code> beginnen und abschließen\n",
        "\n",
        "import re\n",
        "import markdown\n",
        "\n",
        "def gptparse(text):\n",
        "    # Preprocessing: <br> durch \\n ersetzen,\n",
        "    # dann umwandeln\n",
        "    #\n",
        "    # (Braucht eine Extension, um MD in HTML zu verstehen)\n",
        "    htmltext = markdown.markdown(text.replace(\"\\n\",\"\"),extensions=['md_in_html'])\n",
        "# alte Codeblock-Umwandlung, in case it does not work\n",
        "#    pattern =  r'\\`\\`\\`(?P<text>[^*]+)\\`\\`\\`'\n",
        "#    htmltext = re.sub(pattern, r'<code><pre>\\g<text></pre></code>', text)\n",
        "    return htmltext\n",
        "\n",
        "def gptparse2(previous_messages):\n",
        "    text = \"\"\n",
        "    for item in previous_messages:\n",
        "        if item[\"role\"] == \"assistant\":\n",
        "            p_text = '<p style=\"font-family: Verdana; font-style: italic;\" markdown=\"1\">'\n",
        "            p_text += '<b>Chatbot: </b>'\n",
        "            p_text += item[\"content\"]\n",
        "            p_text += '</p>'\n",
        "            text += markdown.markdown(p_text,extensions=['md_in_html','extra','codehilite','nl2br'])\n",
        "        if item[\"role\"] == \"user\":\n",
        "            p_text = '<p style=\"font-family: Verdana;\" markdown=\"1\">'\n",
        "            p_text += '<b>Du: </b>'\n",
        "            p_text += item[\"content\"]\n",
        "            p_text += '</p>'\n",
        "            text += markdown.markdown(p_text,extensions=['md_in_html','extra','codehilite','nl2br'])\n",
        "    return text\n",
        "\n",
        "# Define the function to be called when the chatbot is used\n",
        "def on_chatbot_button_clicked(button):\n",
        "    global chatbot_output\n",
        "    # Get the user's input and display it\n",
        "    user_input = user_text.value\n",
        "    user_text.value = ''\n",
        "    # Generate a response from the chatbot\n",
        "    chatbot_output_area.value += f'<p style=\"font-family: Verdana;\" markdown=\"1\"><b>Du</b>: {user_input}</p>'\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            *previous_messages,\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ]\n",
        "    chatbot_output_area.value += '<p style=\"font-family: Verdana; font-style: italic;\" markdown=\"1\"><b>Chatbot: </b>'\n",
        "    # Stream-Objekt mit der Antwort\n",
        "    chatbot_response = chatbot(messages)\n",
        "    collected_messages = []   # braucht man nicht zwingend\n",
        "    # Anzahl von Tokens mit der User-Frage initiieren\n",
        "    chunk_tokens = calculate_tokens(user_input)\n",
        "    # Iteriere über die Chunks (die Brocken )\n",
        "    for chunk in chatbot_response:\n",
        "        chunk_message = chunk['choices'][0]['delta']  # extract the message\n",
        "        collected_messages.append(chunk_message)  # save the event response\n",
        "        # Ausgabefenster: Neuen Chunk anhängen\n",
        "        chatbot_output = chunk_message.get('content', '')\n",
        "        # /n durch <br> ersetzen\n",
        "        chatbot_output_area.value += re.sub('\\r?\\n','<br>',chatbot_output)\n",
        "        update_token_usage_widget(calculate_tokens(chatbot_output))\n",
        "    # Stream-HTML-Block abschließen...\n",
        "    chatbot_output_area.value += '</p>'\n",
        "    # Antwort komplett in die Chathistorie aufnehmen\n",
        "    chatbot_output = ''.join([m.get('content', '') for m in collected_messages])\n",
        "    previous_messages.extend([\n",
        "        {\"role\": \"user\", \"content\": user_input},\n",
        "        {\"role\": \"assistant\", \"content\": chatbot_output},\n",
        "    ])\n",
        "    # ... und Code neu formatieren\n",
        "    chatbot_output_area.value = gptparse2(previous_messages)\n",
        "    # ...und die Länge in Tokens berechnen und ergänzen\n",
        "\n",
        "def pricing(tokens):\n",
        "    price = models_token_info.get(model)['pricing']\n",
        "    # Kosten in Dollar zurückgeben\n",
        "    return(tokens * price / 1000)\n",
        "\n",
        "\n",
        "# Define the chatbot input and output widgets\n",
        "user_text = widgets.Text(\n",
        "    placeholder='...',\n",
        "    description='You:',\n",
        "    layout=widgets.Layout(width='60%'),\n",
        ")\n",
        "\n",
        "# Definiere den Absenden-Button und binde ihn an on_chatbot_button_clicked\n",
        "chatbot_button = widgets.Button(\n",
        "    description='Send',\n",
        "    layout=widgets.Layout(width='15%'),\n",
        ")\n",
        "chatbot_reset = widgets.Button(\n",
        "    description = 'Reset',\n",
        "    layout=widgets.Layout(width='15%')\n",
        ")\n",
        "##### Der eigentliche Code! #####\n",
        "\n",
        "from getpass import getpass\n",
        "key_needed = True\n",
        "while key_needed:\n",
        "    openai.api_key = getpass(\"Enter OpenAI API Key here: \")\n",
        "    try:\n",
        "        # Testweise Modelle abfragen\n",
        "        models = openai.Model.list()['data']\n",
        "        # Erfolg?\n",
        "        print(\"API Key is valid!\")\n",
        "        key_needed = False\n",
        "    except:\n",
        "        print(\"Query error - invalid API key maybe?\")\n",
        "previous_messages = []\n",
        "spent_tokens = 0        # Wie viele Tokens wurden bisher über die API abgefragt?\n",
        "spent_dollars = 0.00    # Zu welchem Preis?\n",
        "codeblock = False       # Hat Ausgabe eines Codeblocks begonnen?\n",
        "\n",
        "# Die Einstellungs-Widgets anzeigen\n",
        "# Setzt die globalen Variablen temperature, system_prompt, api_key, model, stoptokens\n",
        "display(slider_temperature,\n",
        "#        slider_bestof,\n",
        "        dropdown_model,\n",
        "        textbox_stop,\n",
        "        textbox_max_tokens,\n",
        "        area_system)\n",
        "\n",
        "# Die Eingabefelder registrieren\n",
        "\n",
        "chatbot_button.on_click(on_chatbot_button_clicked)\n",
        "chatbot_reset.on_click(on_chatbot_reset_clicked)\n",
        "# Abschicken auch durch Return in der user_text Box\n",
        "user_text.on_submit(on_chatbot_button_clicked)\n",
        "\n",
        "\n",
        "# Display the chatbot widgets\n",
        "display(text_tokens)\n",
        "display(chatbot_output_area, user_text, chatbot_button, chatbot_reset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Known issues\n",
        "\n",
        "- Might drop the last couple of characters if you type too fast, and press Enter too fast.\n",
        "- The token usage calculation is an approximation as streamed return data gives no usage information"
      ],
      "metadata": {
        "id": "H5ilOJwzv6Tw"
      }
    }
  ]
}