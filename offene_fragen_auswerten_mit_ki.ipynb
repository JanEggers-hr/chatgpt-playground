{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyNSpLBLUEtvh+jUZqDOV6gz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/chatgpt-playground/blob/main/offene_fragen_auswerten_mit_ki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Offene Fragen auswerten mit KI\n",
        "\n",
        "**Antworten auf offene Fragen kategorisieren und sortieren**\n",
        "\n",
        "Dieses Colab nimmt die Antworten aus Freitext-Feldern - und versucht sie mit KI-Hilfe zu kategorisieren.\n",
        "\n",
        "## Was man braucht\n",
        "- Ein Google-Konto (oder eine lokale juPyter-Installation), um den Code ausführen zu können\n",
        "- Ein API-Token der OpenAI-KI\n",
        "- Eine Excel-Tabelle mit den Freitext-Antworten\n",
        "\n",
        "### Das Format der Excel-Tabelle\n",
        "\n",
        "| ID | Text Frage 1 | Text Frage 2 | Text Frage 3 | ... |\n",
        "|---:|:------------:|:-------------:|:----:|:---|\n",
        "| 1 | Antwort | Antwort | |\n",
        "| 3 |  | Antwort | | |\n",
        "| 6 | Antwort |  | Antwort |\n",
        "\n",
        "## Wie es abläuft\n",
        "\n",
        "- **Block 1** starten: Lädt die OpenAI-Bibliotheken, um mit der KI sprechen zu können, überprüft, welche KI-Modelle genutzt werden können, und legt all die \"Prompts\" fest - die Anweisungen an die KI.\n",
        "- **Block 2** verbindet das Programm mit dem \"Google Drive\" des Nutzers, lädt eine neue Excel-Datei hoch - oder, wenn keine hochgeladen wird, nimmt die letzte aus dem Ordner ```evaluiere-umfragen-tabelle``` auf dem Google Drive/Meine Ablage - und lässt mich eine Spalte der Tabelle auswählen.\n",
        "- **Block 3** analysiert die Antworten und schlägt eine vorgegebene Anzahl von Kategorien vor - und gibt dann\n",
        "\n",
        "## Für die Profis...\n",
        "\n",
        "...befinden sich ganz am Ende des Dokuments Informationen zu Versionsnummer und angedachten Erweiterungen.\n",
        "\n",
        "...gibt es die Möglichkeit, in den Code zu schauen - das lohnt sich insbersondere bei Block 1: Am Ende des KI-Code-Blocks sind alle **Prompts** zu finden - die Anweisungen an die KI. Dort nach Bedarf anpassen, wenn die KI nicht tut, was sie soll!\n",
        "\n",
        "...Informationen zu den verwendeten Temperaturen: Bei der Analyse-Phase kann man sie einstellen. Beim Kategorisierungs-Schritt steht sie auf 0 - um möglichst reproduzierbare Ergebnisse zu haben. Ganz ausgeschaltet ist der Zufall trotzdem nicht.\n"
      ],
      "metadata": {
        "id": "1_46PotrvXDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Block 1: KI einrichten\n",
        "import requests\n",
        "import json\n",
        "import math\n",
        "import markdown\n",
        "\n",
        "# ipywidgets ist schon installiert\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Modelle und Kosten definieren\n",
        "# Kosten in US-Dollar je 1000 Tokens\n",
        "# Könnte die Modelle auch über die API holen, aber so kann ich die Kosten\n",
        "# mitgeben. Entsprechend OpenAI-Preisliste Dezember 2023. https://openai.com/pricing\n",
        "# Output ist inzwischen doppelt so teuer wie Input. Hier werden die Output-\n",
        "# Preise zur Berechnung genutzt.\n",
        "models_token_info = {\n",
        "          'gpt-4-0125-preview': {\n",
        "                                        'output_price': 0.03,\n",
        "                                        'input_price': 0.01,\n",
        "                                        'max_tokens': 128000,\n",
        "                                        'info': 'Standard-GPT4'\n",
        "                                      },\n",
        "          'gpt-3.5-turbo-0125': {\n",
        "                                        'output_price': 0.0015,\n",
        "                                        'input_price': 0.0005,\n",
        "                                        'max_tokens': 16385,\n",
        "                                        'info': 'Standard-GPT3.5'\n",
        "                                      },\n",
        "                    'gpt-4': {\n",
        "                                        'output_price': 0.06,\n",
        "                                        'input_price': 0.03,\n",
        "                                        'max_tokens': 16384,\n",
        "                                        'info': 'Teuerere GPT4-Variante (2x)'\n",
        "                                      },\n",
        "                    'gpt-3.5-turbo-instruct': {\n",
        "                                        'output_price': 0.002,\n",
        "                                        'input_price': 0.0015,\n",
        "                                        'max_tokens': 4096,\n",
        "                                        'info': 'Auf Instruktionen optimierte GPT3.5-Variante mit kleinem Kontext'\n",
        "                                      },\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Tokenizer Tiktoken einbinden\n",
        "!pip install -q tiktoken\n",
        "import tiktoken\n",
        "print(\"Tokenizer tiktoken geladen.\")\n",
        "\n",
        "# OpenAI-API-Library einbinden\n",
        "!pip install -q openai\n",
        "from openai import OpenAI\n",
        "print(\"OpenAI-API-Library geladen.\")\n",
        "\n",
        "##### Der eigentliche Code! #####\n",
        "\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "key_needed = True\n",
        "try:\n",
        "  ai_key_name = userdata.get('openai')\n",
        "  ai_client = OpenAI(api_key = userdata.get(ai_key_name))\n",
        "except:\n",
        "  print(\"OpenAI-Key benötigt\")\n",
        "else:\n",
        "  print(\"*** API-Key gültig, KI einsatzbereit! ***\")\n",
        "  key_needed = False\n",
        "\n",
        "while key_needed:\n",
        "    try:\n",
        "        # Testweise Modelle abfragen\n",
        "        ai_client = OpenAI(api_key = getpass(\"OpenAI-API-Key eingeben: \"))\n",
        "        models = ai_client.models.list()\n",
        "        # Returns a list of model objects\n",
        "        # Erfolg?\n",
        "        print(\"API-Key gültig!\")\n",
        "        print(\"Wenn du willst, kannst du den Key als Colab-Secret hinterlegen\")\n",
        "        print(\"(unter dem Schlüsselchen am linken Rand). Er wird dort sicher und\")\n",
        "        print(\"nur für dich in deinem Account gespeichert.\\n\")\n",
        "        print(\"Zwei Secrets müssen angelegt werden:\")\n",
        "        print(\"- ein Key mit dem OpenAI-API-Key (z.B.: 'openaikey1': 'sk-abcd123...')\")\n",
        "        print(\"- ein Key 'openai', der den Namen des Secrets mit dem Key bekommt \")\n",
        "        print(\"  (im Beispiel: 'openai': 'openaikey1')\")\n",
        "        print(\"\\nDu darfst den Key aber gern auch jedesmal neu eingeben.\")\n",
        "        key_needed = False\n",
        "    except Exception as e:\n",
        "        print(\"Fehler bei Abfrage; ist der API-Key möglicherweise ungültig?\", e)\n",
        "\n",
        "previous_messages = []\n",
        "spent_tokens = 0        # Wie viele Tokens wurden bisher über die API abgefragt?\n",
        "spent_dollars = 0.00    # Zu welchem Preis?\n",
        "tokens_input = 0\n",
        "tokens_output = 0\n",
        "\n",
        "\n",
        "# Define the HTML and JavaScript code for the spinner animation\n",
        "spinner_html = \"\"\"\n",
        "<div class=\"loader\"></div>\n",
        "<style>\n",
        ".loader {\n",
        "  border: 8px solid #f3f3f3;\n",
        "  border-top: 8px solid #3498db;\n",
        "  border-radius: 50%;\n",
        "  width: 25px;\n",
        "  height: 25px;\n",
        "  animation: spin 2s linear infinite;\n",
        "  margin: 20px auto;\n",
        "}\n",
        "\n",
        "@keyframes spin {\n",
        "  0% { transform: rotate(0deg); }\n",
        "  100% { transform: rotate(360deg); }\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Funktion, die das Sprachmodell direkt anzapft (für Preprocessing und Kategorienbildung)\n",
        "# Braucht: Systemprompt, Beispiele (als User-Assistant-Dialog), Modell\n",
        "# Gibt zurück: einen String\n",
        "# Updated die verbrauchten Tokens.\n",
        "\n",
        "# Hilfsfunktion: Token berechnen\n",
        "def calculate_tokens(string: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    # cl100k_base ist der Tokenizer für Davinci, GPT-3 und GPT-4\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def output_pricing(tokens,model):\n",
        "    price = models_token_info.get(model)['output_price']\n",
        "    # Kosten in Dollar zurückgeben\n",
        "    return(tokens * price / 1000)\n",
        "\n",
        "def input_pricing(tokens,model):\n",
        "    price = models_token_info.get(model)['input_price']\n",
        "    # Kosten in Dollar zurückgeben\n",
        "    return(tokens * price / 1000)\n",
        "\n",
        "def gpt(g_system,g_previous_messages,g_prompt,g_model,temperature = 0,json=False,max_tokens=None):\n",
        "    # Systemprompt und few-shots zusammenbinden\n",
        "    #\n",
        "    global spent_tokens\n",
        "    global spent_dollars\n",
        "    if json==True:\n",
        "        m_type = {\"type\": \"json_object\"}\n",
        "    else:\n",
        "        m_type = {\"type\": \"text\"}\n",
        "\n",
        "    prompts = [\n",
        "            {\"role\": \"system\", \"content\": g_system},\n",
        "            *g_previous_messages,\n",
        "            {\"role\": \"user\", \"content\": g_prompt},\n",
        "        ]\n",
        "    response = ai_client.chat.completions.create(\n",
        "        messages=prompts,\n",
        "        model=g_model,\n",
        "        # max_tokens=max_tokens,\n",
        "        n=1,\n",
        "        response_format= m_type,\n",
        "        stream = False,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    # Anzahl verbrauchtert Tokens anpassen\n",
        "    spent_tokens += response.usage.total_tokens\n",
        "    tokens_input = response.usage.prompt_tokens\n",
        "    tokens_output =  response.usage.completion_tokens\n",
        "    spent_dollars += output_pricing(tokens_output,model) + input_pricing(tokens_input,model)\n",
        "    token_usage_text = f'<b>Verbrauchte Token:</b> {spent_tokens} ($ {spent_dollars:.3f}) '\n",
        "    return(response.choices[0].message.content)\n",
        "\n",
        "### Liste der verfügbaren Modelle anpassen ###\n",
        "all_models = ai_client.models.list()\n",
        "all_model_names = [model.id for model in all_models.data]\n",
        "for key in list(models_token_info.keys()):\n",
        "    if key not in all_model_names:\n",
        "        del models_token_info[key]\n",
        "        print(f\"OpenAI-Modell {key} für diesen API-Key leider nicht verfügbar\")\n",
        "    else:\n",
        "        print(f\"Modell {key} verfügbar: {models_token_info[key]['info']}\")\n",
        "\n",
        "##############################################################################\n",
        "##############################################################################\n",
        "##############################################################################\n",
        "# PROMPTS - die Anweisungen an die KI\n",
        "#\n",
        "# Hier kannst du anpassen, welche Anweisungen die KI bekommt.\n",
        "\n",
        "##############################################################################\n",
        "# Das Analyse-Prompt:\n",
        "# Im ersten KI-Schritt schaut das Sprachmodell auf eine Stichprobe von Antworten\n",
        "# und versucht, daraus Kategorien vorzuschlagen.\n",
        "#\n",
        "# Als Funktion, um zur Laufzeit die Anzahl der gewünschten Kategorien und die Frage\n",
        "# vorzugeben.\n",
        "\n",
        "def analyse_prompt(kategorien,frage):\n",
        "    analyse_system = f\"\"\"Du bist Meinungsforscher.\n",
        "    Dies sind Antworten auf die Frage: '{frage}'\n",
        "    Fasse bitte die Antworten in {kategorien} Kategorien zusammen. Die Kategorien\n",
        "    können Inhalte benennen. Sie sollten eine Kategorie 'Sonstiges'\n",
        "    enthalten und eine Kategorie, die Antworten markiert, die an der Frage vorbeigehen.\n",
        "    Beschreibe die Kategorien ausführlich und trennscharf. Liste die ausführlichen\n",
        "    Beschreibungen der Kategorien fortlaufend nummeriert auf. Erzeuge ein JSON mit\n",
        "    Kategorie, Beschreibung der Form: {{'ID': {{'Kategorie': text, 'Beschreibung': text}} }}.\n",
        "    \"\"\"\n",
        "    return(analyse_system)\n",
        "\n",
        "##############################################################################\n",
        "# Preprocess: Leere und unsinnige Antworten markieren, um sie zu filtern\n",
        "#\n",
        "# WIRD DERZEIT GAR NICHT GENUTZT, BUT HEY!\n",
        "\n",
        "def preprocess_prompt(p,frage):\n",
        "    preprocess_system = f\"Du bist Meinungsforscher. \\\n",
        "    Dies sind Antworten auf die Frage: '{frage}' \\\n",
        "    Nenne die Nummern der Antworten, die keine Angaben \\\n",
        "    machen oder nicht zu verstehen sind. Antworte mit einem JSON.\"\n",
        "    sample_input=\"\"\"1073 |\n",
        "    1099 | wieß nicht\n",
        "    1101 | keine Meinung\"\"\"\n",
        "    sample_output=\"{'1073': True, '1099': True, '1101': True }\"\n",
        "    preprocess_samples = [\n",
        "              {\"role\": \"user\", \"content\": sample_input},\n",
        "              {\"role\": \"assistant\", \"content\": sample_output},\n",
        "          ]\n",
        "    p_filter_text = gpt(preprocess_system,preprocess_samples,p,model,json=True)\n",
        "    p_filters = [int(num) for num in re.findall(r'\\d+', p_filter_text)]\n",
        "    return(p_filters)\n",
        "\n",
        "##############################################################################\n",
        "# Das Prüf-Prompt:\n",
        "#\n",
        "# Die KI soll bewerten, wie gut brauchbar die Kategorien sind. Hat derzeit nur\n",
        "# Informationscharakter.\n",
        "\n",
        "def feedback_prompt(frage):\n",
        "  pruef_prompt = f\"\"\"Du bist Meinungsforscher. Du beurteilst Kategorien, \\\n",
        "  die Antworten auf diese Frage zusammenfassen: \\\n",
        "  '{frage}' Die Kategorien sollen eindeutig, \\\n",
        "  klar definiert und trennscharf sein. \\n\\\n",
        "  Sichte die vorgeschlagenen Kategorien und bewerte jede Kategorie in Hinblick \\\n",
        "  darauf, ob sie klar definiert und eindeutig ist, auf einer \\\n",
        "  Skala von 0 (unzureichend) bis 10 (perfekt).\n",
        "  Sichte dann die Bewertungen. Bei Werten von 6 oder weniger \\\n",
        "  mach einen Vorschlag zur Verbesserung, zum Beispiel eine Aufteilung in \\\n",
        "  eindeutige Kategorien.\"\"\"\n",
        "  return pruef_prompt\n",
        "\n",
        "##############################################################################\n",
        "# Die Kategorisierungs-Funktion:\n",
        "#\n",
        "# Ordnet die übergebenen Antworten zur Frage in die Kategorien ein,\n",
        "# orientiert sich dabei an vorgegebenen Beispielen (\"few-shot\").\n",
        "# Gibt ein JSON zurück.\n",
        "\n",
        "def kategorisiere(textblock,\n",
        "                  kat_text,\n",
        "                  samples,\n",
        "                  antwort,\n",
        "                  model,\n",
        "                  frage):\n",
        "  kat_system = f\"\"\"\n",
        "  Du bist Meinungsforscher.\n",
        "  Du bekommst Antworten auf die Frage: '{frage}'.\n",
        "  Prüfe für jede Antwort, ob sie den folgenden Kategorien entspricht.\n",
        "  ###\n",
        "  {kat_text}\n",
        "  ###\n",
        "  Untersuche jede Antwort und beantworte\n",
        "  für jede Kategorie, ob die Antwort in diese Kategorie passt.\n",
        "  Antworte mit einem JSON mit dem Index ID und einer Liste für alle Kategorien\n",
        "  mit Elementen der Form: {{'A': True}} oder {{'A': False}}.\n",
        "  \"\"\"\n",
        "  kat_sample = [\n",
        "      {\"role\": \"user\", \"content\": samples},\n",
        "       {\"role\": \"assistant\", \"content\": antwort},\n",
        "\n",
        "  ]\n",
        "#  print(kat_system)\n",
        "#  print(kat_sample)\n",
        "#  print(textblock)\n",
        "  result = gpt(kat_system,\n",
        "               kat_sample,\n",
        "               textblock,\n",
        "               g_model = model,\n",
        "               # Temperatur 0 - wir wollen Reproduzierbarkeit!\n",
        "               temperature=0,\n",
        "               json= True)\n",
        "#  # Gib einen String zurück\n",
        "#  print(\"-------------\")\n",
        "#  print(result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "7A0rpaKpfGXx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dauert eine Weile, bis alle Bibliotheken geladen sind - aber diesen Schritt braucht es, damit wir die KI einsetzen können. Wenn das Notebook die Verbindung zum Colab-Server verloren hat, muss man bei dieser Zelle noch einmal anfangen und alles neu ausführen - Colab merkt sich keine Zwischenstände, wenn die \"Laufzeit\" (der virtuelle Rechner) stoppt.\n",
        "\n",
        "Wer etwas an den KI-\"Prompts\" ändern will: Sie finden sich oben im Block 1 ganz am Ende des Codes! Auch für Nicht-Programmierer - Änderungen einfach an den roten Texten zwischen den Dreifach-Anführungszeichen-Zeilen ``` \"\"\" ``` durchführen. (Alles Grüne mit einem ``` # ``` vorneweg sind Kommentare, die der Computer ignoriert.)\n",
        "\n",
        "## Jetzt: Daten laden!\n",
        "\n",
        "Google Drive ist der Cloud-Speicherplatz, den jedes Google-Konto nutzen kann - wie eine Dropbox oder Nextcloud.\n",
        "\n",
        "Hochgeladene .XLSX-Dateien legt das Programm im Google-Drive Verzeichnis ```gdrive/MyDrive/evaluiere-umfragen-tabelle``` ab. (Von dort holt es sich auch die jeweils neueste Datei, wenn man keine Datei hochlädt.)\n"
      ],
      "metadata": {
        "id": "Tv55WtunBdn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Block 2: Daten laden\n",
        "\n",
        "from google.colab import files, drive\n",
        "# Connect to Google Drive to export data\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import glob\n",
        "import json\n",
        "import markdown\n",
        "from datetime import datetime\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"/content/gdrive/MyDrive/evaluiere-umfragen-tabelle\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "if not os.path.exists(output_dir + \"/ergebnisse\"):\n",
        "    os.mkdir(output_dir + \"/ergebnisse\")\n",
        "\n",
        "os.chdir(output_dir)\n",
        "\n",
        "def upload_and_load_excel():\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        file_name = next(iter(uploaded))\n",
        "        path = io.BytesIO(uploaded[file_name])\n",
        "        # Laden der Excel-Datei in ein Pandas DataFrame\n",
        "        df = pd.read_excel(path, index_col=0)  # Hier wird angenommen, dass die erste Spalte als Index dient\n",
        "        return df\n",
        "    else:\n",
        "        # Letzte xlsx-Datei im Pfad\n",
        "        xlsx_files = glob.glob(os.path.join(\"./\", '*.xlsx'))\n",
        "        most_recent_file = max(xlsx_files, key=os.path.getctime)\n",
        "        df = pd.read_excel(most_recent_file, index_col=0)\n",
        "        return df\n",
        "\n",
        "df = upload_and_load_excel()\n",
        "if df is not None:\n",
        "    dropdown_spalte = widgets.Dropdown(\n",
        "        options = df.columns,\n",
        "        description = 'Spalte:',\n",
        "        disabled = False,\n",
        "        layout = widgets.Layout(width=\"50%\")\n",
        "    )\n",
        "    text_spalte = widgets.HTML(\n",
        "        value=\"\"\n",
        "    )\n",
        "    def d_eventhandler(change):\n",
        "      global df_clean\n",
        "      global column_name\n",
        "      column_name = dropdown_spalte.value\n",
        "      series = df[column_name]\n",
        "      df_clean = series.dropna()  # Entfernen von leeren Zellen\n",
        "      text_spalte.value = f\"enthält {len(df_clean)} Zeilen\"\n",
        "    dropdown_spalte.observe(d_eventhandler,'value')\n",
        "    # 1x ausführen, um erste Spalte anzuzeigen\n",
        "    d_eventhandler(0)\n",
        "    hbox_spalte = widgets.HBox([dropdown_spalte, text_spalte])\n",
        "    display(hbox_spalte)"
      ],
      "metadata": {
        "id": "JF0eY4T6f9AE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wenn ich eine Spalte auswähle, kriege ich angezeigt, wie viele Zeilen sie enthält - nachdem die leeren Antworten ausgefiltert wurden.\n",
        "\n",
        "## Analyse: Die KI Kategorien vorschlagen und feedbacken lassen\n",
        "\n",
        "Im weiteren arbeitet das Programm **nur mit den Daten aus der hier ausgewählten Spalte** - wer die anderen Spalten analysiert haben will, muss ab Block 3 nochmal durchlaufen lassen!\n",
        "\n",
        "* Ein Klick auf den Knopf **Analyse** zieht eine Stichprobe aus den Antworten - bis zu 500 - und lässt die KI die vorgegebene Anzahl Kategorien vorschlagen.\n",
        "* Ein Klick auf den Knopf **Feedback** lässt die KI prüfen, für wie trennscharf und präzise sie die vorgeschlagenen Kategorien hält.\n",
        "\n",
        "Dabei kann man einstellen:\n",
        "* Das Modell - die stärkere KI (GPT4-...) oder die schnellere (GPT3.5-turbo...)?\n",
        "* Die Temperatur - wie viel Zufall lassen wir zu; wie unvorhersehbar soll das Sprachmodell antworten?\n",
        "\n",
        "Die vorgeschlagenen Kategorien kann man direkt hier anpassen - oder etwas bequemer im nächsten Schritt.\n",
        "\n",
        "Wer mag, kann Kategorien auch selbst eintragen, ohne KI - die allerdings als \"Markdown\"-Tabelle formatiert sein sollten, also so:\n",
        "```\n",
        "| ID | Kategorie | Beschreibung |\n",
        "|----|-----------|--------------|\n",
        "| 1  | Sonstiges | Alles, was nicht klar einer der anderen Kategorien zuzuordnen ist |\n",
        "```\n",
        "(Das hier kann man als Kopiervorlage nutzen!)"
      ],
      "metadata": {
        "id": "kLIQX5h5sDDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Block 3: Analyse und Einteilung\n",
        "#\n",
        "\n",
        "# Debugging-View\n",
        "debug_view = widgets.Output(layout={'border': '1px solid black'})\n",
        "# Beispielabfrage\n",
        "# @debug_view.capture(clear_output=True)\n",
        "\n",
        "\n",
        "import markdown\n",
        "\n",
        "kategorien = 10\n",
        "max_samples = 500\n",
        "if len(df_clean) > max_samples:\n",
        "  max_samples = len(df_clean)\n",
        "\n",
        "# Das Interface\n",
        "\n",
        "# Konstanten\n",
        "wid90 = widgets.Layout(width=\"90%\")\n",
        "wid80 = widgets.Layout(width=\"80%\")\n",
        "wid50 = widgets.Layout(width=\"50%\")\n",
        "wid40 = widgets.Layout(width=\"40%\")\n",
        "wid30 = widgets.Layout(width=\"30%\")\n",
        "\n",
        "# Slider für die Temperatur (Default: 0.3)\n",
        "slider_temperatur = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0,\n",
        "    max=1.5,\n",
        "    step=0.1,\n",
        "    description='Temperatur:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout = wid50\n",
        ")\n",
        "\n",
        "\n",
        "# Slider für die Anzahl der Kategorien (Default: 10)\n",
        "slider_kategorien = widgets.IntSlider(\n",
        "    value=10,\n",
        "    min=5,\n",
        "    max=20,\n",
        "    description='Kategorien:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    # Weite begrenzen, damit der Readout mit angezeigt wird\n",
        "    layout=wid90\n",
        ")\n",
        "\n",
        "slider_samples = widgets.IntSlider(\n",
        "    value=100,\n",
        "    min=20,\n",
        "    max=max_samples,\n",
        "    description='Stichprobe:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout = wid90\n",
        ")\n",
        "\n",
        "textbox_max_tokens = widgets.Text(\n",
        "    value='0',\n",
        "    placeholder='0',\n",
        "    description='Max. Token:',\n",
        ")\n",
        "\n",
        "text_tokens = widgets.HTML(\n",
        "    value = f'<b>Samples in Token</b>: 0 '\n",
        ")\n",
        "\n",
        "dropdown_model = widgets.Dropdown(\n",
        "    # Nimm die oben definierte Preisliste als Basis\n",
        "    options=list(models_token_info.keys()),\n",
        "    value=list(models_token_info.keys())[0],\n",
        "    description='Modell:',\n",
        ")\n",
        "\n",
        "area_system = widgets.Textarea(\n",
        "    value = analyse_prompt(kategorien,column_name),\n",
        "    rows=10,\n",
        "    description = 'Kategorien:'\n",
        ")\n",
        "\n",
        "\n",
        "area_kategorien = widgets.Textarea(\n",
        "    value = '(noch keine Kategorien)',\n",
        "    rows=15,\n",
        "    description = ''\n",
        ")\n",
        "\n",
        "html_samples_tokens = widgets.HTML(\n",
        "    value = ''\n",
        ")\n",
        "\n",
        "button_analyse = widgets.Button(\n",
        "    description='KI-Vorschlag',\n",
        "    tooltip = 'Die KI auf Basis der Stichprobe Kategorien-Vorschläge machen lassen',\n",
        "    layout = wid80\n",
        ")\n",
        "\n",
        "button_feedback = widgets.Button(\n",
        "    description='KI-Feedback',\n",
        "    tooltip = 'Fragt die KI, wie es die derzeitigen Kategorien einschätzt',\n",
        "    layout = wid80\n",
        ")\n",
        "\n",
        "html_status = widgets.HTML(value =\"\")\n",
        "\n",
        "# Definiere Output - um später das Tab neu löschen zu können\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "\n",
        "stoptokens=\"\"\n",
        "\n",
        "# Funktion wird bei Veränderung ausgeführt\n",
        "def update_params(change):\n",
        "    global temperature\n",
        "    global max_tokens\n",
        "    global system_prompt\n",
        "    global model\n",
        "    global stoptokens\n",
        "    global best_of\n",
        "    global kategorien\n",
        "    global samples_n\n",
        "    global prepare_prompt\n",
        "    global token_limit_reached\n",
        "    column_name = dropdown_spalte.value\n",
        "    # Token-Obergrenze umrechnen\n",
        "    try:\n",
        "        max_tokens = int(textbox_max_tokens.value)\n",
        "        if max_tokens == 0:\n",
        "            max_tokens = None\n",
        "    except ValueError:\n",
        "        max_tokens = None\n",
        "    textbox_max_tokens.value = f'{max_tokens}'\n",
        "    system_prompt = area_kategorien.value\n",
        "    model = dropdown_model.value\n",
        "    if (stoptokens == \"\"):\n",
        "      stoptokens = None\n",
        "    temperatur = slider_temperatur.value\n",
        "    kategorien = slider_kategorien.value\n",
        "    area_system.value = analyse_prompt(kategorien,column_name)\n",
        "    samples_n = slider_samples.value\n",
        "    if samples_n > len(df_clean):\n",
        "        samples_n = len(df_clean)\n",
        "        slider_samples.max = samples_n\n",
        "\n",
        "    prepare_prompt = df_clean.sample(n=samples_n).to_markdown()\n",
        "    sample_tokens = calculate_tokens(prepare_prompt)\n",
        "    token_limit_reached = (sample_tokens > models_token_info.get(model)['max_tokens'] * 0.9)\n",
        "    if token_limit_reached:\n",
        "        text_tokens.value = f'<b style=\"color:red\">Samples in Token: {sample_tokens} - ÜBER DEM LIMIT</b>'\n",
        "    else:\n",
        "        text_tokens.value = f'<b>Samples in Token: {sample_tokens} </b>'\n",
        "\n",
        "\n",
        "########################\n",
        "\n",
        "# Verbinde die Widgets mit der Funktion zur Verarbeitung der Werte\n",
        "slider_kategorien.observe(update_params, 'value')\n",
        "slider_samples.observe(update_params, 'value')\n",
        "# Datensatz in ein JSON verwandeln\n",
        "\n",
        "\n",
        "# Auswertungsfunktionen für die Kategorien:\n",
        "# - Erster Durchlauf: Markiere die Nicht-Antworten\n",
        "kategorien = 10\n",
        "\n",
        "@debug_view.capture(clear_output=True)\n",
        "def prepare_categories(p):\n",
        "    global kategorien\n",
        "    global prepare_prompt\n",
        "    global kat_json\n",
        "    # Spalte\n",
        "    column_name = dropdown_spalte.value\n",
        "    html_samples_tokens.value = f\"Verbrauchte Tokens: {spent_tokens}, {spent_dollars:.2f} $\"\n",
        "    prepare_prompt = \"\"\n",
        "    prepare_samples = []\n",
        "    prepare_prompt = p.to_json(orient=\"index\")\n",
        "    prepare_system = analyse_prompt(kategorien,column_name)\n",
        "    print(prepare_system)\n",
        "    print(prepare_prompt)\n",
        "    html_status.value = spinner_html + f\"<b>Starte Analyse</b> mit Prompt: <small>{prepare_prompt[:100]}</small>\"\n",
        "    # Spinner einschalten\n",
        "    model = dropdown_model.value\n",
        "    kategorien_vorschlaege = gpt(prepare_system,\n",
        "                                prepare_samples,prepare_prompt,model,json=True)\n",
        "    # Vorschlags-String in Tabelle umwandeln und die anzeigen\n",
        "    # Erst ein dict\n",
        "    print(\"---Output---\")\n",
        "    print(kategorien_vorschlaege)\n",
        "    kat_json = json.loads(kategorien_vorschlaege)\n",
        "    # ...dann daraus ein Dataframe und das in Markdown\n",
        "    area_kategorien.value = pd.DataFrame.from_dict(kat_json,orient=\"index\").to_markdown()\n",
        "    html_samples_tokens.value = f\"Verbrauchte Tokens: {spent_tokens}, {spent_dollars:.2f} $\"\n",
        "    html_status.value = \"Kategorien in Tabelle umgewandelt\"\n",
        "\n",
        "#    html_status.close()\n",
        "#    area_kategorien.display()\n",
        "\n",
        "def generiere_kategorien(change):\n",
        "    global df_clean\n",
        "    global frage\n",
        "    # Wird nur ausgeführt, wenn Token-Limit noch nicht erreicht ist\n",
        "    if not (token_limit_reached):\n",
        "    # Stichprobe von n Samples aus den Antworten ziehen (stellt man mit dem\n",
        "    # Slider ein)\n",
        "        sample_df = df_clean.sample(n=samples_n)\n",
        "        prepare_categories(sample_df)\n",
        "\n",
        "def generiere_feedback(change):\n",
        "    if (area_kategorien.value == \"\") or area_kategorien.value == \"(noch keine Kategorien)\":\n",
        "      html_status.value = \"<i>Keine Kategorien angelegt!</i>\"\n",
        "      return False\n",
        "    html_status.value = \"<b>Überprüfe Kategorien...</b>\"+spinner_html\n",
        "    model=list(models_token_info.keys())[0]\n",
        "    # Hole Feedback von der KI: Sind die Kategorien trennscharf und\n",
        "    # hinreichend bestimmt?\n",
        "    # Gibt derzeit nur einen Text zurück - für die Zukunft: Vorschläge\n",
        "    # im Editor markieren.\n",
        "    pruefe_vorschlag = gpt(feedback_prompt(dropdown_spalte.value),\n",
        "     [],area_kategorien.value,\n",
        "                            g_model=model,temperature = 0.5,json=False)\n",
        "    html_status.value = \"<h2>GPT-4 schätzt die Kategorien so ein: </h2>\" + markdown.markdown(pruefe_vorschlag, extensions=['tables'])\n",
        "    return pruefe_vorschlag\n",
        "\n",
        "# Bereite die Kategorien vor.\n",
        "button_analyse.on_click(generiere_kategorien)\n",
        "button_feedback.on_click(generiere_feedback)\n",
        "\n",
        "# Die Einstellungs-Widgets anzeigen\n",
        "# Setzt die globalen Variablen temperature, system_prompt, api_key, model, stoptokens\n",
        "display(dropdown_model)\n",
        "# Widget mit der Anzahl an Kategorien anzeigen (Default = 10)\n",
        "\n",
        "update_params(0)\n",
        "vbox_analyse = widgets.VBox([slider_kategorien,\n",
        "        slider_samples,\n",
        "        button_analyse,\n",
        "        button_feedback],\n",
        "                            layout=wid40)\n",
        "hbox_kategorien = widgets.HBox([vbox_analyse, area_kategorien])\n",
        "display(slider_temperatur)\n",
        "display(text_tokens)\n",
        "display(hbox_spalte)\n",
        "display(html_samples_tokens)\n",
        "\n",
        "\n",
        "# Ergebnistext über volle Breite\n",
        "area_kategorien.layout.width = '100%'\n",
        "display(html_status)\n",
        "display(hbox_kategorien)\n"
      ],
      "metadata": {
        "id": "d7UBtRQzaeCf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Einverstanden mit den Kategorien?** Die Anzahl und die Definition wie gewünscht oben abändern; dabei bitte keine leeren Zeilen einfügen bzw. Neudefinitionen mit laufender Nummer am Ende ergänzen\n",
        "\n",
        "Wenn alles so passt: Weiter mit dem nächsten Block 4!\n",
        "\n",
        "## Kategorien testen und anpassen - mit Beispielen\n",
        "\n",
        "Im nächsten Schritt probieren wir an einigen Beispielen aus, wie die KI mit diesen Kategorien arbeitet. Die Kategorisierungen können wir von Hand anpassen (und auch die Kategorie-Definitionen können wir hier noch ändern, um zusätzliche Kategorien ergänzen oder Kategorien löschen.)\n",
        "\n",
        "Warum die Mühe? Sprachmodelle arbeiten besser, wenn man ihnen an einigen Beispielen zeigt, wie sie arbeiten sollen - \"few-shot learning\" nennen das KI-Leute. Die Beispiele und das gewünschte Ergebnis werden bei der Kategorisierung mit übergeben."
      ],
      "metadata": {
        "id": "0-PKG1tIrX-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Block 4: Kategorien testen und Beispiel-Kategorisierungen verbessern\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "import re\n",
        "\n",
        "chk_samples_n = 5\n",
        "slider_beispiele = widgets.IntSlider(\n",
        "    value=5,\n",
        "    min=3,\n",
        "    max=10,\n",
        "    description='Beispiele:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout = wid50\n",
        ")\n",
        "\n",
        "def update_chk_samples(v):\n",
        "  global chk_samples_n\n",
        "  global chk_samples_df\n",
        "  global tab_samples\n",
        "  chk_samples_n = slider_beispiele.value\n",
        "  # Neue Samples ziehen\n",
        "  chk_samples_df = df_clean.sample(n=chk_samples_n)\n",
        "  generate_raster()\n",
        "  generate_samples_list()\n",
        "  tab_samples = create_tabs()\n",
        "  output.clear_output()\n",
        "  with output:\n",
        "    display(tab_samples)\n",
        "\n",
        "\n",
        "\n",
        "slider_beispiele.observe(update_chk_samples)\n",
        "# Globale Variable kategorien enthält die Anzahl der Kategorien laut Schieberegler,\n",
        "# muss auf tatsächliche Anzahl gesetzt werden\n",
        "kategorien_text = area_kategorien.value\n",
        "\n",
        "# Splitte die tabelle in einzelne Teilen; Trennzeile raus.\n",
        "# Den String mit dem Markdown-Code in Zeilen zerlegen\n",
        "# kat_df enthält dann die Kategorien mit einer Kategorie-ID\n",
        "zeilen = [line.strip() for line in kategorien_text.strip().split(\"\\n\") if line.strip() and not all(c in '-|:' or c.isspace() for c in line)]\n",
        "kategorien = len(zeilen)-1\n",
        "\n",
        "def kat_strip(string):\n",
        "  strings = string.split(\"|\")\n",
        "  strings2 = [s.strip() for s in strings[2:]]\n",
        "  return \": \".join(strings2)\n",
        "\n",
        "kat_df = pd.DataFrame([kat_strip(string) for string in zeilen[1:]])\n",
        "\n",
        "############## POINT OF NO RETURN ################\n",
        "# Ab hier werden die Kategorien in dieser Zelle bearbeitet; jedes Mal,\n",
        "# wenn eine Kategorie gelöscht oder neu geschaffen wird, wird die Tabelle neu aufgebaut\n",
        "\n",
        "# Slider nochmal anpassen - falls man die Kategorien nochmal nachtunen will\n",
        "slider_kategorien.value = kategorien\n",
        "# Alte GUI-Elemente weg\n",
        "slider_kategorien.close()\n",
        "area_kategorien.close()\n",
        "slider_temperatur.close()\n",
        "slider_samples.close()\n",
        "hbox_kategorien.close()\n",
        "\n",
        "# Definiere Output - um später das Tab neu löschen zu können\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "# Beispiele ziehen\n",
        "chk_samples_df = df_clean.sample(n=chk_samples_n)\n",
        "\n",
        "\n",
        "print(\"In diesem Abschnitt haben Sie die Möglichkeit, der Maschine beim Einordnen der Antworten zu helfen.\")\n",
        "print()\n",
        "print(\"Wir haben ein paar Zufalls-Antworten gezogen. Sie können sie entweder von Hand kategorisieren, \")\n",
        "print(\"wie Sie es mit den Kategorien tun würden, oder auf 'Testen' klicken - dann versucht die KI,\")\n",
        "print(\"die Beispiele einzuordnen. Klicken Sie sich durch die Beispiel-Tabs und korrigieren Sie nach.\")\n",
        "print(\"Auch die Definitionen lassen sich noch verbessern. Wenn Sie zufrieden sind, können Sie weitergehen.\")\n",
        "\n",
        "display(slider_beispiele)\n",
        "html_status2 = widgets.HTML(\"\")\n",
        "\n",
        "# Das Auswahlraster generieren\n",
        "# Arbeitet mit den globalen Variablen:\n",
        "# - labels (Liste mit Textboxen für die Kategorien)\n",
        "# - raster (Liste von Listen bzw. Array mit den Checkboxen)\n",
        "\n",
        "\n",
        "# Erst mal: Die Labels, für jede Kategorie eins.\n",
        "# Dienen ab hier auch als Speicher für die Kategorien.\n",
        "def generate_labels():\n",
        "    global labels\n",
        "    global kategorien\n",
        "    kategorien = len(kat_df)\n",
        "    labels = [widgets.Text(value = kat_df[0][i],layout=wid50) for i in range(kategorien)]\n",
        "\n",
        "\n",
        "# Dann das Raster: Für jedes Sample eine Zeile, für jede Spalte eine Kategorie.\n",
        "def generate_raster():\n",
        "    global raster\n",
        "    raster = []\n",
        "    raster = [[widgets.Checkbox(value=False,\n",
        "                                description=\"trifft zu\") for j in range(kategorien)] for i in range(chk_samples_n)]\n",
        "\n",
        "# Zu kategorisierende Texte aktualisieren\n",
        "def generate_samples_list():\n",
        "  global html_samples_list\n",
        "  global chk_samples_df\n",
        "  html_samples_list = [widgets.HTML(f\"<h2>Zu kategorisierender Text:</h2> <b><i>>>{s}<<</i></b>\")for s in chk_samples_df]\n",
        "  return html_samples_list\n",
        "\n",
        "\n",
        "# Jetzt die Tabs generieren und anzeigen: VBox von HBoxes.\n",
        "def make_all_tabs():\n",
        "  # Für jedes Sample ein Child-Element anlegen:\n",
        "  # - Erste Zeile: Label mit dem Sample-Text\n",
        "  # - Dann für jede Kategorie eine HBox mit Kategorie und Checkbox\n",
        "  global all_tabs\n",
        "  all_tabs = []\n",
        "  global html_samples_list\n",
        "  for i in range(chk_samples_n):\n",
        "    # Liste anlegen\n",
        "    rows = [html_samples_list[i]]\n",
        "    for j in range(kategorien):\n",
        "      rows.append(widgets.HBox([labels[j],raster[i][j]]))\n",
        "    all_tabs.append(widgets.VBox(rows))\n",
        "\n",
        "def create_tabs():\n",
        "  make_all_tabs()\n",
        "  # Jetzt das Tab-Element generieren und anzeigen\n",
        "  tab = widgets.Tab(\n",
        "      children = all_tabs,\n",
        "      titles = [f\"Beispiel {i+1}\" for i in range(chk_samples_n)]\n",
        "  )\n",
        "  for i in range(chk_samples_n):\n",
        "    tab.set_title(i, f\"Beispiel {i+1}\")\n",
        "  return tab\n",
        "\n",
        "def generate_all():\n",
        "  generate_samples_list()\n",
        "  generate_labels()\n",
        "  generate_raster()\n",
        "  tab = create_tabs()\n",
        "  return tab\n",
        "\n",
        "def check_empty(raster):\n",
        "  for row in raster:\n",
        "      # Iterate through each checkbox in the row\n",
        "      for checkbox in row:\n",
        "          # Check if the checkbox is checked (True)\n",
        "          if checkbox.value:\n",
        "              # If any checkbox is checked, return False\n",
        "              return False\n",
        "  # If all checkboxes are unchecked, return True\n",
        "  return True\n",
        "\n",
        "# Hilfsfunktion: Alle Checkboxen auf False setzen\n",
        "def reset_check(v):\n",
        "  for row in raster:\n",
        "    for checkbox in row:\n",
        "      checkbox.value = False\n",
        "\n",
        "# Hilfsfunktion: eine Kategorie aus dem Checkboxen-Raster löschen\n",
        "def raster_remove(kat):\n",
        "    global raster\n",
        "    for row in raster:\n",
        "      del row[kat]\n",
        "\n",
        "# Hilfsfunktion: Textboxen in kat_df umkopieren; labels anpassen\n",
        "def update_kat():\n",
        "  global kat_df\n",
        "  global labels\n",
        "  kat_liste = [kat.value for kat in labels]\n",
        "  kat_df = pd.DataFrame(kat_liste)\n",
        "\n",
        "# Hilfsfunktion: label-Textboxen in Kategorien-String-Liste\n",
        "def chk_kat_new():\n",
        "  kat_new = \"\"\n",
        "  i = 0\n",
        "  for l in labels:\n",
        "    kat_new = kat_new + chr(65+i) + \". | \" + l.value + \"\\n\"\n",
        "    i = i + 1 # All-Time Classic!\n",
        "  return kat_new\n",
        "\n",
        "# Hilfsfunktion: Aus raster ein Dictionary als fewshot-Beispiel machen\n",
        "def create_fewshot(raster):\n",
        "      # JSON mit den Antworten generieren\n",
        "    d = {}\n",
        "    # Reihen haben wir immer.\n",
        "    # Steppe durch die Indices des Dict.\n",
        "    for y in range(len(raster)):\n",
        "      row_list = []\n",
        "      for kat in range(len(raster[y])):\n",
        "        kat_key = chr(kat + 65) # 'A' ff.\n",
        "        row_list.append({kat_key: raster[y][kat].value})\n",
        "      d[f\"{y}\"] = row_list\n",
        "    return d\n",
        "\n",
        "# Hilfsfunktion: JSON in Raster verwandeln\n",
        "# Nimmt einen JSON-String.\n",
        "# Gibt ein df mit Bool-Werten und den Indizes der Zeilen zurück\n",
        "def rasterize(json_str1):\n",
        "    d = json.loads(json_str1)\n",
        "    # neues Dataframe anlegen - Spalten A, B, C... (für Kategorien)\n",
        "    global labels\n",
        "    column_names = [chr(k+ord(\"A\")) for k in range(len(labels))]\n",
        "    df = pd.DataFrame(columns = column_names).astype(bool)\n",
        "    df.index.name = \"ID\"\n",
        "    # Durch alle Keys (ID) des Root-Directorys gehen.\n",
        "    # Sei json_str ein JSON der Form: { '1': [T,F,T], '2': [F,T,T]}\n",
        "    # oder { '1': [{'A': T}, {'B':T}] }\n",
        "    # oder { '1': [{'A': T, 'B': F}], '2': {'A': F, 'B': T} }\n",
        "    # oder { '1': [F, T, T, F, T, T, F]}\n",
        "    # oder { '1':{'A': F, 'B': T, 'C':F}, '2': {'A': F, 'B': T} }\n",
        "    #\n",
        "    for idx in d.keys():\n",
        "    # Zusatz: Ignoriere leere Keys.\n",
        "    # Kam immer wieder vor, dass das Sprachmodell einen leeren Key ausspuckt.\n",
        "      if idx != \"\":\n",
        "        zeile = d[idx]\n",
        "        # Isch scho Lischde?\n",
        "        if isinstance(zeile,list):\n",
        "          # Prüfe erstes Element: Dictionary?\n",
        "          if isinstance(zeile[0],dict):\n",
        "            # JSON flach machen - Liste in einzelne Dict-Einträge konvertieren\n",
        "            flattened_dict = {list(d.keys())[0]: list(d.values())[0] for d in zeile}\n",
        "            new_df = pd.DataFrame(flattened_dict,index=[idx]).astype(bool)\n",
        "            # Oder einzelnes Element: dann einfach die Liste zuweisen\n",
        "          else:\n",
        "            new_df = pd.DataFrame([zeile], columns = column_names, index = [idx]).astype(bool)\n",
        "          df = pd.concat([df,new_df],ignore_index=False)\n",
        "        # Die Zeile kann auch ein dict sein statt einer Liste\n",
        "        elif isinstance(zeile,dict):\n",
        "          new_df = pd.DataFrame(zeile, index = [idx]).astype(bool)\n",
        "          df = pd.concat([df,new_df],ignore_index=False)\n",
        "        else: # Einzelelement?\n",
        "          print(zeile,\"kann nicht verarbeitet werden?\")\n",
        "    # Zur Sicherheit: NaN-Werte - kein Eintrag - werden durch False ersetzt\n",
        "    df.fillna(False, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Beispielabfrage\n",
        "# Druckt viele Debug-Informationen, die aber alle im Objekt debug_view landen.\n",
        "# Wenn man Debug-Daten braucht, kann man es sich über debug_view anzeigen lassen.\n",
        "@debug_view.capture(clear_output=True)\n",
        "def evaluate(value):\n",
        "  global chk_samples_df\n",
        "  global tab_samples\n",
        "  global html_samples_list\n",
        "  chk_samples_df.name=\"Antwort\"\n",
        "  global beispielantwort\n",
        "  # Die Checkboxen auslesen und in ein Beispiel-JSON packen,\n",
        "  # außer sie sind alle leer.\n",
        "  output.clear_output()\n",
        "  if check_empty(raster):\n",
        "    beispiele = \"\"\n",
        "    beispielantwort = \"\"\n",
        "  else:\n",
        "    # Es gibt schon Bewertungen: übergib die existierenden als Beispiel und die\n",
        "    # existierenden Bewertungen als Beispielantwort - als Few Shot.\n",
        "    # Dann n neue Beispiele ziehen und existierende mit der ANtwort übergeben\n",
        "    # Erst mal: Index 0, 1, 2... (passend zu den Few-Shots)\n",
        "    chk_samples_df.reset_index(drop=True, inplace=True)\n",
        "    beispiele = chk_samples_df.to_markdown()\n",
        "    # JSON mit den Antworten aus raster generieren\n",
        "    d = create_fewshot(raster)\n",
        "    beispielantwort = json.dumps(d)\n",
        "    # Beispiel und passende Antworten sind übergeben; jetzt neue Samples ziehen\n",
        "    chk_samples_df = df_clean.sample(n=chk_samples_n)\n",
        "    chk_samples_df.index.name=\"ID\"\n",
        "    # Index 0, 1, 2, 3, 4 - für stimmige Beispiele\n",
        "    chk_samples_df.name = \"Antwort\"\n",
        "    # Liste mit den neuen Beispielen als HTML-Titel\n",
        "    generate_samples_list()\n",
        "  # Nochmal die Kategorien anpassen (aus augenblicklichen Labels-Textboxen)\n",
        "  update_kat()\n",
        "  # Unseren Spinner nutzen\n",
        "  html_status2.value=\"<h2>Evaluiere die Beispiele...\"+spinner_html\n",
        "  print(\"---Kategorien aus chk_kat_new---\")\n",
        "  print(chk_kat_new())\n",
        "  print(\"---Few-Shot---\")\n",
        "  print(beispiele)\n",
        "  print(beispielantwort)\n",
        "  print(\"---Samples---\")\n",
        "  print(chk_samples_df.to_markdown)\n",
        "  # Modell abfragen\n",
        "  json_str = kategorisiere(textblock = chk_samples_df.to_markdown(),\n",
        "                kat_text = chk_kat_new(),\n",
        "                  samples = beispiele,\n",
        "                  antwort = beispielantwort,\n",
        "                  model = dropdown_chk_model.value,\n",
        "                  frage=column_name)\n",
        "  print(f\"---Input Tokens: {tokens_input} Output Tokens: {tokens_output}---\")\n",
        "  print(\"---json_str---\")\n",
        "  print(json_str)\n",
        "  html_status2.value=\"Update Beispiele...\"\n",
        "  # Aus dem JSON ein Raster von Boolean-Werten\n",
        "  # Funktion gibt ein df zurück, das\n",
        "  values = rasterize(json_str).values.tolist()\n",
        "  # Rüberkopieren auf die Checkboxes\n",
        "  for y in range(len(values)):\n",
        "    v = values[y]\n",
        "    for x in range(len(v)):\n",
        "      raster[y][x].value = v[x]\n",
        "  ### Update der Tabs ###\n",
        "  html_status2.value=f\"Beispiel-Kategorien für Frage: {column_name}\"\n",
        "  html_samples_tokens.value = f\"Verbrauchte Tokens: {spent_tokens}, {spent_dollars:.2f} $\"\n",
        "  # Update der Tabelle und der Tab-Spaltentexte\n",
        "  # Eigentlich sollte man die nur neu generieren, aber offensichtlich\n",
        "  # erneuern sich die HBox- und VBox-Elemente nicht, also nochmal anzeigen\n",
        "  tab_samples = create_tabs()\n",
        "  with output:\n",
        "    display(tab_samples)\n",
        "\n",
        "\n",
        "dropdown_chk_model = widgets.Dropdown(\n",
        "    # Nimm die oben definierte Preisliste als Basis\n",
        "    options=list(models_token_info.keys()),\n",
        "    value=list(models_token_info.keys())[1],\n",
        "    description='Modell:',\n",
        ")\n",
        "\n",
        "button_chk_evaluate = widgets.Button(\n",
        "    description = \"Testen\",\n",
        "    tooltip = \"Lässt die KI die Kategorien auf n Beispiele anwenden\"\n",
        ")\n",
        "button_chk_reset = widgets.Button(\n",
        "    description = \"Reset\",\n",
        "    tooltip = \"Löscht alle Checkboxen; Abfrage ohne Nutzer-Vorgabe\"\n",
        ")\n",
        "button_neue = widgets.Button(\n",
        "    description=\"Neue Kategorie\",\n",
        "    tooltip =\"Legt eine neue, leere Kategorie an\"\n",
        ")\n",
        "\n",
        "button_leere = widgets.Button(\n",
        "    description=\"Leere löschen\",\n",
        "                              tooltip = \"Leere Kategorien werden gelöscht\")\n",
        "\n",
        "button_neue.style.button_color = \"#CCC\"\n",
        "button_leere.style.button_color = \"#C99\"\n",
        "\n",
        "\n",
        "def neue_kategorie(v):\n",
        "  global raster\n",
        "  global kat_df\n",
        "  # Das hier legt zwar nur eine Kopie des Pointers auf raster an,\n",
        "  # aber da generate_raster tatsächlich eine neue Liste generiert,\n",
        "  # geht sich das trotzdem aus.\n",
        "  raster_alt = raster\n",
        "  # Index des Dataframes reparieren und neue Zeile\n",
        "  kat_df.reset_index(drop=True, inplace=True)\n",
        "  kat_df.loc[len(kat_df)]=\"\"\n",
        "  generate_labels()\n",
        "  # Neues Raster neu anlegen, alte Raster-Werte kopieren\n",
        "  generate_raster()\n",
        "  for i in range(len(raster_alt)):\n",
        "    for j in range(len(raster_alt[i])):\n",
        "      raster[i][j].value = raster_alt[i][j].value\n",
        "  global tab_samples\n",
        "  tab_samples=create_tabs()\n",
        "  output.clear_output(wait=True)\n",
        "  with output:\n",
        "    display(tab_samples)\n",
        "\n",
        "def leere_kategorien_loeschen(v):\n",
        "  global tab_samples\n",
        "  global kategorien\n",
        "  global kat_df\n",
        "  update_kat()\n",
        "  #Liste aus dem Dataframe\n",
        "  kat_liste = list(kat_df[0])\n",
        "  # raster_remove\n",
        "  # Rückwärts zählen, um das Raster bei mehrfachen Kategorie-Löschungen\n",
        "  # nicht durcheinander zu bringen\n",
        "  for i in range(len(kat_liste)-1,-1,-1):\n",
        "    if kat_liste[i] == \"\":\n",
        "    # Leere Spalten aus dem Chkbox-Raster löschen\n",
        "      raster_remove(i)\n",
        "      kat_df = kat_df.drop(i)\n",
        "  # Index für Kategorien neu aufbauen\n",
        "  kat_df.reset_index(drop=True, inplace=True)\n",
        "  kategorien = len(kat_liste)\n",
        "  generate_labels()\n",
        "  tab_samples=create_tabs()\n",
        "  output.clear_output()\n",
        "  with output:\n",
        "    display(tab_samples)\n",
        "\n",
        "\n",
        "# widgets.tab(children=, titles=)\n",
        "# Jedes Child als VBox aus: Titelzeile, HBox Prompt und Checkbox.\n",
        "# Umwandlungs-Funktion Checkboxen-Grid-Values und JSON\n",
        "# Das für später: Einstellen der Anzahl der Shots\n",
        "tab_samples = generate_all()\n",
        "\n",
        "button_chk_evaluate.on_click(evaluate)\n",
        "# Die Observes für den Text-Update\n",
        "button_chk_reset.on_click(reset_check)\n",
        "button_neue.on_click(neue_kategorie)\n",
        "button_leere.on_click(leere_kategorien_loeschen)\n",
        "\n",
        "hbox_eval = widgets.HBox([dropdown_chk_model,button_chk_evaluate,button_chk_reset,button_neue, button_leere])\n",
        "display(html_samples_tokens)\n",
        "display(hbox_eval)\n",
        "display(html_status2)\n",
        "display(output)\n",
        "with output:\n",
        "  display(tab_samples)\n"
      ],
      "metadata": {
        "id": "3JjmTCC5JxJf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wenn alle Beispiele so kategorisiert sind, wie du es dir vorstellst, kann die Auswertung beginnen.\n",
        "\n",
        "Dabei werden die Antworten in Blöcken der festgelegten Größe an die KI übergeben - das erlaubt eine wesentlich schnellere und kosteneffizientere Verarbeitung. Zu groß sollten die Blöcke nicht werden. Derzeit gehe ich davon aus, dass eine Blockweite von 30 in Ordnung ist - und GPT4 vermutlich auch mit 50 klar kommt. Voreingestellt sind 25.\n",
        "\n",
        "Während der nächste Block verarbeitet wird, kann man sich anschauen, wie die KI die letzten Antworten bewertet hat.\n",
        "\n",
        "**Das dauert dann schon ein paar Minuten.** Bitte daran denken: Ein zu lange unbewachtes Colab meldet sich ab! Browsererweiterungen wie [Colab Automatic Clicker](https://addons.mozilla.org/de/firefox/addon/colab-automatic-clicker/) (Firefox) und [Colab Keep Alive](https://chromewebstore.google.com/detail/google-colab-keep-alive/bokldcdphgknojlbfhpbbgkggjfhhaek) (Chrome) helfen."
      ],
      "metadata": {
        "id": "8B93enk09dxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Block 5: Auswertung und Datei-Export\n",
        "from math import floor\n",
        "\n",
        "\n",
        "slider_blockweite = widgets.IntSlider(\n",
        "    value=25,\n",
        "    min=5,\n",
        "    max=50,\n",
        "    description='Blockweite:',\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout = wid50\n",
        ")\n",
        "\n",
        "def update_blockweite(v):\n",
        "  global blockweite\n",
        "  blockweite = slider_blockweite.value\n",
        "\n",
        "slider_blockweite.observe(update_blockweite)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Fortschrittsbalken!\n",
        "progress = widgets.IntProgress(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=len(df_clean),\n",
        "    description='Fortschritt',\n",
        "    bar_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    layout=wid50\n",
        ")\n",
        "\n",
        "# Eigentliche Abfrage der KI - als Funktion, um debuggen zu können\n",
        "@debug_view.capture(clear_output=False)\n",
        "def test_block(myblock_df,kat_text,beispiele,beispielantwort):\n",
        "    print(\"---Kategorien aus chk_kat_new---\")\n",
        "    print(chk_kat_new())\n",
        "    print(\"---Few-Shot---\")\n",
        "    print(beispiele)\n",
        "    print(beispielantwort)\n",
        "    print(\"---Block---\")\n",
        "    print(myblock_df.to_markdown())\n",
        "    myjson_str = kategorisiere(textblock = myblock_df.to_markdown(),\n",
        "                  kat_text = kat_text,\n",
        "                    samples = beispiele,\n",
        "                    antwort = beispielantwort,\n",
        "                    model = dropdown_chk_model.value,\n",
        "                    frage = column_name)\n",
        "    print(\"---JSON---\")\n",
        "    print(myjson_str)\n",
        "    return myjson_str\n",
        "\n",
        "# Haupt-Funktion\n",
        "def starte_evaluation(v):\n",
        "    # Variable als global definieren, um sie ggf. retten zu können\n",
        "    global auswertung_df\n",
        "    debug_view.clear_output()\n",
        "    # Steppe durch die Aussagen, blockweise.\n",
        "    # Hier geht's los\n",
        "    blockweite = slider_blockweite.value\n",
        "    z_dict = {}\n",
        "    model = dropdown_chk_model.value\n",
        "    df_clean.index.name=\"ID\"\n",
        "    df_clean.name=\"Antwort\"\n",
        "    #display(dropdown_model, button_starten)\n",
        "    print(f\"Modell: {model}, Blockweite: {blockweite}\")\n",
        "    button_start_eval.close()\n",
        "    slider_blockweite.close()\n",
        "    html_info = widgets.HTML(value =f\"Los geht's! Blöcke zu {blockweite} Kommentaren - Ergebnis wird angezeigt\")\n",
        "    display(html_samples_tokens)\n",
        "    display(progress)\n",
        "    display(html_info)\n",
        "    html_info.value = \"Auswertung beginnt... \" + spinner_html\n",
        "    # Die Beispiele final auslesen und nutzen\n",
        "    # Vorher den Index resetten, damit die Beispiel-Bewertungs-Indizes passen\n",
        "    chk_samples_df.reset_index(drop=True, inplace=True)\n",
        "    chk_samples_df.index.name=\"ID\"\n",
        "    chk_samples_df.name = \"Antwort\"\n",
        "    beispiele = chk_samples_df.to_markdown()\n",
        "    # Hier werden die Raster-Settings in eine Tabelle gelesen, die dann als\n",
        "    # Beispielantwort angezeigt wird\n",
        "    d = {}\n",
        "    for y_str in range(chk_samples_n):\n",
        "      row_list = [raster[y_str][x].value for x in range(len(raster[y_str]))]\n",
        "      d[str(y_str)] = row_list\n",
        "    beispielantwort = json.dumps(d)\n",
        "    kat_text = chk_kat_new()\n",
        "    html_info.value = spinner_html\n",
        "    auswertung_df = pd.DataFrame()\n",
        "    # Antworten in Blöcke aufteilen\n",
        "    for i in range(floor(len(df_clean)/blockweite)):\n",
        "      idx = blockweite * i\n",
        "      block_df = df_clean[idx:idx+blockweite]\n",
        "      # Hier die KI-Abfrage mit Protokoll-Funktion\n",
        "      # Extra-Funktion, um Ausgabe auffangen zu können\n",
        "      # Prüfe, ob korrektes JSON - wenn nein, versuch nochmal\n",
        "      # (Kommt leider ab und zu vor, dass GPT3.5 kein korrektes JSON ausspuckt)\n",
        "      no_valid_json = True\n",
        "      attempts = 3\n",
        "      while no_valid_json:\n",
        "        json_str = test_block(block_df,\n",
        "                            kat_text,\n",
        "                            beispiele,\n",
        "                            beispielantwort)\n",
        "        try:\n",
        "          t_df = json.loads(json_str)\n",
        "        except:\n",
        "          print(\"Kein gültiges JSON von der KI erzeugt - versuche es nochmal\")\n",
        "          attempts = attempts - 1\n",
        "          if attempts <= 0:\n",
        "              raise Exception(\"KI gibt ungültiges JSON zurück\")\n",
        "        else:\n",
        "          try:\n",
        "            t_df = rasterize(json_str)\n",
        "          except:\n",
        "            print(\"Rasterisierung scheitert, versuche es nochmal\")\n",
        "            attempts = attempts - 1\n",
        "            if attempts <= 0:\n",
        "                raise Exception(\"Rasterisierung gescheitert\")\n",
        "          else:\n",
        "            # alles shiny\n",
        "            no_valid_json = False\n",
        "        # Fortschrittsbalken und Verbrauchsanzeige\n",
        "        html_samples_tokens.value = f\"Verbrauchte Tokens: {spent_tokens}, {spent_dollars:.2f} $\"\n",
        "      progress.value = idx + blockweite\n",
        "      # Zum Anzeigen ein DF mit den Antworten\n",
        "      t_df.index.name = \"ID\"\n",
        "      # Braucht numerischen Index, NaNs abfischen und dann konvertieren\n",
        "      t_df.index = t_df.index.astype('str')\n",
        "      t_df.index = t_df.index.astype('int64')\n",
        "      # Antworten und Kategorisierung vereinen\n",
        "      tt_df = pd.merge(block_df,t_df,left_index=True,right_index=True)\n",
        "      html_info.value=spinner_html + f\"\"\"<small>\n",
        "      {tt_df.to_html()}</small>\"\"\"\n",
        "      # Dataframe auswertung_df verlängern\n",
        "      auswertung_df = pd.concat([auswertung_df,t_df])\n",
        "      # z_dict zur Sicherheit mitführen\n",
        "      if json.loads(json_str) != {}:\n",
        "        z_dict.update(json.loads(json_str))\n",
        "\n",
        "    # Alle Blöcke durch.\n",
        "    # Fortschrittsbalken darf ins Ziel\n",
        "    progress.value = idx + blockweite\n",
        "    print(\"Auswertung abgeschlossen.\")\n",
        "    # Spinner und Tabellen-Infos löschen\n",
        "    html_info.value = \"\"\n",
        "    # Dateinamen erstellen, problematische Zeichen rausschmeißen\n",
        "    sanitized = re.sub(r'[<>:\"/\\\\|?*]', '', column_name)\n",
        "    a_fname = \"./ergebnisse/\"+sanitized+\".xlsx\"\n",
        "    # Die Antwort-Kategorien als Spaltennamen\n",
        "    # Ersetzungstabelle bauen\n",
        "    replacement_names = {f\"{chr(n+ord('A'))}\": labels[n].value for n in range(len(labels))}\n",
        "    auswertung_df.rename(columns=replacement_names, inplace=True)\n",
        "    auswertung_df.to_excel(a_fname, index=True)\n",
        "    # Ergebnis exportieren\n",
        "    html_info.value = f\"\"\"\n",
        "    <h2>Ergebnistabelle fertig zum Download</h2>\n",
        "    Erste fünf Zeilen: <br>\n",
        "    {auswertung_df.head(5).to_html}\n",
        "    Datei <code>{a_fname}</code> wird heruntergeladen\n",
        "    \"\"\"\n",
        "    files.download(a_fname)\n",
        "    print(\"Done.\")\n",
        "\n",
        "button_start_eval = widgets.Button(description = \"Start\",\n",
        "                                   tooltip = \"Starte Auswertung aller Antworten mit den Einstellungen\")\n",
        "\n",
        "button_start_eval.on_click(starte_evaluation)\n",
        "\n",
        "display(dropdown_chk_model)\n",
        "display(slider_blockweite)\n",
        "display(widgets.Label(\"Letzte Möglichkeit, oben die Kategorien anzupassen!\"))\n",
        "display(button_start_eval)"
      ],
      "metadata": {
        "id": "mxGE0oPWihds",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(a_fname)"
      ],
      "metadata": {
        "id": "AgBHpViyZvV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V1.0\n",
        "\n",
        "## Bugs und bekannte Probleme\n",
        "- Checkt vor der Kategorisierung noch nicht das Kontextfenster!\n",
        "- Manchmal kommen die Kategorien im falschen JSON-Format raus - das wird noch nicht abgefangen.\n",
        "- Maximal 26 Kategorien - wird aber nicht überprüft\n",
        "\n",
        "## Nice to have\n",
        "- Vor-Kategorisierung der \"grauen Kategorie\" (nix zum Thema)\n",
        "\n",
        "## Versionsgeschichte\n",
        "\n",
        "### V1.0beta2, 24.2.2024\n",
        "- Sicherheitsprüfung, falls weniger Antworten als Samples\n",
        "- Funktioniert jetzt auch ohne Secret\n",
        "\n",
        "### V1.0beta, 13.2.2024\n",
        "- Excel-Dateien hochladen; Spalten auswerten\n",
        "- Editor, um Kategorien und Einordnungs-Beispiele anzupassen\n",
        "- Fortschrittsbalken\n"
      ],
      "metadata": {
        "id": "fY8vHntYjm6j"
      }
    }
  ]
}