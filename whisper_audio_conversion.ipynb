{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/chatgpt-playground/blob/main/whisper_audio_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnkbc476IMEf"
      },
      "source": [
        "# Whisper-based audio-to-text conversion\n",
        "\n",
        "Runs OpenAI's \"Whisper\" TTS library in a Colab. Nothing is uploaded to OpenAI's servers, everything is processed within the Colab (e.g. in the Google Cloud).\n",
        "\n",
        "Press the small \"Play\" triangle button under the headline \"Code\" - the notebook starts by loading loads and loads into the Colab environment. (Don't worry, this does not concern your computer!) As soon as the loading is done, you are asked to select and upload a file, then the file is converted to a .txt file and downloaded to your download folder.\n",
        "\n",
        "## Tips for running this colab\n",
        "\n",
        "- Activate the GPU in the colab environment (menu \"Runtime\"/\"Change Runtime type\") - this speeds up the Whisper conversion immensely\n",
        "- Use a browser plugin like [Colab Auto Clicker](https://addons.mozilla.org/en-US/firefox/addon/colab-automatic-clicker/) for Firefox to hold the connection to the Notebook while it's doing the work, and leave the browser tab open\n",
        "\n",
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwP0tQN_dHaH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "# Start by getting these two audio libraries (we will need them for conversion)\n",
        "!apt install -q ffmpeg\n",
        "!pip install -q pydub\n",
        "\n",
        "\n",
        "# ipywidgets for setting the parameters\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Preparations: Make work directory\n",
        "output_dir = \"/content/audio/\"\n",
        "# Create output directory\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "os.chdir(output_dir)\n",
        "\n",
        "# You may select\n",
        "# -the library used for conversion (Whisper vs. whisper-jax)\n",
        "# -the size of the model (fast vs. good)\n",
        "\n",
        "lib = 'whisper-jax'\n",
        "model = 'medium'\n",
        "textmode = 'Text only'\n",
        "get_going = False\n",
        "\n",
        "dropdown_library = widgets.Dropdown(\n",
        "    options=['whisper','whisper-jax'],\n",
        "    value=lib,\n",
        "    description='Library:',\n",
        "    layout=widgets.Layout(width='240px')\n",
        ")\n",
        "\n",
        "dropdown_model = widgets.Dropdown(\n",
        "    options=['small','medium','large-v3'],\n",
        "    value=model,\n",
        "    description='Model:',\n",
        "    layout=widgets.Layout(width='240px')\n",
        ")\n",
        "\n",
        "dropdown_textmode = widgets.Dropdown(\n",
        "    options=['Text only','Text+Timestamp'],\n",
        "    value=textmode,\n",
        "    description='Output:',\n",
        "    layout=widgets.Layout(width='240px')\n",
        ")\n",
        "\n",
        "\n",
        "def usage_text(lib,model,textmode):\n",
        "  if lib == \"whisper-jax\":\n",
        "    lib_str = f\"<b>Using the {lib} library</b>: Takes longer to load but converts many times faster\"\n",
        "  else:\n",
        "    lib_str = \"<b>Using the whisper library</b>: Takes about 0.5x-2x the audio length to convert\"\n",
        "  if model == \"small\":\n",
        "    model_str = \"<b>Using small model</b>: less precise but faster\"\n",
        "  elif model == \"medium\":\n",
        "    model_str = \"<b>Using medium model</b>: average precision and conversion time\"\n",
        "  elif model == \"large-v3\":\n",
        "    model_str = \"<b>Using most recent large model</b>: large file download, long runtime, but more precise\"\n",
        "  if textmode == \"Text only\":\n",
        "    textmode_str = \"<b>Text only</b>: Plaintext file without timestamps\"\n",
        "  else:\n",
        "    textmode_str = \"<b>Text+Timestamps</b>: Runs 2x and produces CSV with timestamps and line breaks\"\n",
        "  return(lib_str + \"<br>\" + model_str + \"<br>\" + textmode_str)\n",
        "\n",
        "text_explainer = widgets.HTML(\n",
        "    value = usage_text(lib,model,textmode)\n",
        ")\n",
        "\n",
        "button_start = widgets.Button(\n",
        "    description='Load the model',\n",
        "    layout=widgets.Layout(width='15%'),\n",
        ")\n",
        "\n",
        "def update_params(change):\n",
        "    global lib\n",
        "    global model\n",
        "    global textmode\n",
        "    global get_going\n",
        "    model = dropdown_model.value\n",
        "    lib = dropdown_library.value\n",
        "    text_explainer.value = usage_text(lib,model,textmode)\n",
        "    get_going = False\n",
        "\n",
        "def update_textmode(change):\n",
        "    global textmode\n",
        "    global lib\n",
        "    global model\n",
        "    textmode = dropdown_textmode.value\n",
        "    text_explainer.value = usage_text(lib,model,textmode)\n",
        "\n",
        "# HTML code for a spinning wheel showing the computer at work\n",
        "spinner_html = \"\"\"\n",
        "<div class=\"loader\"></div>\n",
        "<style>\n",
        ".loader {\n",
        "  border: 8px solid #f3f3f3;\n",
        "  border-top: 8px solid #3498db;\n",
        "  border-radius: 50%;\n",
        "  width: 25px;\n",
        "  height: 25px;\n",
        "  animation: spin 2s linear infinite;\n",
        "  margin: 20px auto;\n",
        "}\n",
        "\n",
        "@keyframes spin {\n",
        "  0% { transform: rotate(0deg); }\n",
        "  100% { transform: rotate(360deg); }\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "def button_clicked(button):\n",
        "    global get_going\n",
        "    print(\"Installing libraries for conversion (may take some time)\")\n",
        "    # Display the spinner animation\n",
        "    html_spinner = widgets.HTML(spinner_html)\n",
        "    display(html_spinner)\n",
        "    global pipeline\n",
        "    if lib == \"whisper-jax\":\n",
        "        !pip install -q git+https://github.com/sanchit-gandhi/whisper-jax > /dev/null 2>&1\n",
        "        from whisper_jax import FlaxWhisperPipline\n",
        "        # load model (medium)\n",
        "        pipeline = FlaxWhisperPipline(\"openai/whisper-\"+model)\n",
        "    elif lib == \"whisper\":\n",
        "        !pip install -q git+https://github.com/openai/whisper.git > /dev/null 2>&1\n",
        "        import whisper\n",
        "        pipeline = whisper.load_model(model)\n",
        "        # Once the tasks are completed, remove the spinner animation\n",
        "    else:\n",
        "        raise Exception(\"No valid library selected\")\n",
        "    html_spinner.close()\n",
        "    get_going = True\n",
        "\n",
        "def get_transcript(fname):\n",
        "    if lib == \"whisper-jax\":\n",
        "        result = pipeline(fname,\n",
        "                          task=\"transcribe\",\n",
        "                          return_timestamps=True)\n",
        "    else:\n",
        "        result = pipeline.transcribe(fname)\n",
        "    if (textmode != 'Text only'):\n",
        "        text = \"\"\n",
        "        # \"chunks\" is a list of dicts\n",
        "        # each containing:\n",
        "        # - timestamp: (list of 2 timecodes - start & end)\n",
        "        # - text: string\n",
        "        # Converting keys and values to a list, and taking first element\n",
        "        for c in result[\"chunks\"]:\n",
        "            print(c)\n",
        "            c_ts = c[\"timestamp\"]\n",
        "            c_text = c[\"text\"]\n",
        "            text = text + f'{c_ts[0]},{c_ts[1]},\"{c_text}\"\\n'\n",
        "        return(text)\n",
        "    else:\n",
        "        return(result[\"text\"])\n",
        "\n",
        "\n",
        "###################### Upload file and process ########################\n",
        "uploader = widgets.FileUpload(\n",
        "    multiple=True  # Allow multiple files to be selected\n",
        ")\n",
        "\n",
        "def convert_file(change):\n",
        "    if change.new:\n",
        "        if not get_going:\n",
        "            button_clicked(0)\n",
        "        # Now, convert the files\n",
        "        for fname in uploader.value:\n",
        "            file_info = uploader.value[fname]\n",
        "            file_content = file_info['content']\n",
        "            html_spinner = widgets.HTML(spinner_html)\n",
        "            display(html_spinner)\n",
        "            audio_bytes = io.BytesIO(file_content)\n",
        "            # print(f\"Loaded file: {fname}\")\n",
        "            fpath = output_dir + fname\n",
        "            # file extension, slicing away the dot\n",
        "            stem, suffix_raw = os.path.splitext(fpath)\n",
        "            suffix = suffix_raw[1:]\n",
        "            #convert to mp4 (m4a) using pydub\n",
        "            audio = AudioSegment.from_file(audio_bytes,format=suffix)\n",
        "            # print(\"Loaded audio.\")\n",
        "            if lib == \"whisper-jax\":\n",
        "                export_ext = \"mp3\"\n",
        "                audio.export(stem + \".\" + export_ext, format=export_ext)\n",
        "            else:   # whisper needing m4a\n",
        "                export_ext = \"mp4\"\n",
        "                audio.export(stem + \".\" + export_ext, format=export_ext)\n",
        "            # print(f\"Saved as {export_ext}\")\n",
        "            print(\"Starting conversion of audio to text file.\")\n",
        "            audio_fname = stem + \".\" + export_ext\n",
        "            if textmode == \"Text only\":\n",
        "                txt_fname = stem + \".txt\"\n",
        "            else:\n",
        "                txt_fname = stem + \".csv\"\n",
        "            # print(f\"Converting {audio_fname}\")\n",
        "            result = get_transcript(audio_fname)\n",
        "            with open(txt_fname, 'w') as f:\n",
        "              f.write(result)\n",
        "            files.download(txt_fname)\n",
        "            os.remove(audio_fname)\n",
        "        html_spinner.close()\n",
        "        # Remove uploaded file from uploader and from local storage\n",
        "        uploader.value.clear()\n",
        "        print(\"Done - files converted. Saving to the download folder.\")\n",
        "\n",
        "### Widget hooks and display ###\n",
        "\n",
        "dropdown_library.observe(update_params, 'value')\n",
        "dropdown_model.observe(update_params, 'value')\n",
        "dropdown_textmode.observe(update_textmode, 'value')\n",
        "uploader.observe(convert_file,names='value')\n",
        "button_start.on_click(button_clicked)\n",
        "\n",
        "display(dropdown_library,\n",
        "        dropdown_model,\n",
        "        dropdown_textmode,\n",
        "        text_explainer,\n",
        "        uploader\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBKJ8nokdI9z"
      },
      "source": [
        "*v2.1 - based on whisper-jax, and with timestamp output support. Known issue: Downloads CSV twice.*\n",
        "\n",
        "### The Fine Print:\n",
        "\n",
        "By default, this workbook is using the medium-sized model (the multilanguage model is about 5GB); for better accuracy, switch to \"large\" (10GB), for faster transcription, use \"small\" (2GB).\n",
        "\n",
        "Remember to switch on the GPU in Colab - changing the runtime type before executing - or conversion will be really, really slow. **But even with GPU installed, the conversion takes some time** - so be patient! If you should lose connection to the Colab VM, reconnect, and rerun the cell.\n",
        "\n",
        "One thing that Whisper does not do for you: insert paragraphs, line breaks, indentations, emphases. Anything that makes the text block more readable is missing. Sorry."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}